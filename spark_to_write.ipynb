{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-10-12T11:49:05.753851Z",
     "start_time": "2023-10-12T11:49:00.081353Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "23/10/12 17:19:03 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.appName(\"DataPush\") \\\n",
    "    .config(\"spark.driver.extraClassPath\", \"/Users/eashvrudhula/PycharmProjects/Hackathon3/PostgresData/postgresql-42.6.0.jar\").getOrCreate()\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "hackathon_data = spark.read.csv(\"/Users/eashvrudhula/PycharmProjects/Hackathon3/PostgresData/hackathon_data.csv\", header=True, inferSchema=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-12T11:12:53.042222Z",
     "start_time": "2023-10-12T11:12:32.753043Z"
    }
   },
   "id": "90935d78c948a5bb"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _c0: string (nullable = true)\n",
      " |-- job_role: string (nullable = true)\n",
      " |-- job_description: string (nullable = true)\n",
      " |-- skills: string (nullable = true)\n",
      " |-- soft_skills: string (nullable = true)\n",
      " |-- responsibility: string (nullable = true)\n",
      " |-- location_name: string (nullable = true)\n",
      " |-- talent_cost: string (nullable = true)\n",
      " |-- currency_code: string (nullable = true)\n",
      " |-- currency: string (nullable = true)\n",
      " |-- experience: string (nullable = true)\n",
      " |-- experience_range: string (nullable = true)\n",
      " |-- ready_for_application: string (nullable = true)\n"
     ]
    }
   ],
   "source": [
    "hackathon_data.printSchema()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-12T11:12:53.055807Z",
     "start_time": "2023-10-12T11:12:53.043648Z"
    }
   },
   "id": "a8972d92090a9bef"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def write_data_jdbc(df, database, table, environment, server=GATEWAY,\n",
    "                        read_connection_config=read_postgres_config, **kwargs):\n",
    "        env_dict = {\"production\": \"prod\",\n",
    "                    \"qa\": \"qa\",\n",
    "                    \"development\": \"dev\",\n",
    "                    \"dev\": \"dev\",\n",
    "                    \"prod\": \"prod\"\n",
    "                    }\n",
    "        environment = env_dict[environment]\n",
    "        hostname, port, username, password, driver = read_connection_config(environment, server=server,\n",
    "                                                                            database=database, access_mode=\"write\")\n",
    "        driver = \"postgresql\"\n",
    "\n",
    "        url = \"jdbc:{0}://{1}:{2}/{3}?user={4}&password={5}\".format(driver, hostname, port, database, username,\n",
    "                                                                    password)\n",
    "        properties = {\n",
    "            \"user\": username,\n",
    "            \"password\": password,\n",
    "            \"driver\": \"org.postgresql.Driver\"\n",
    "        }\n",
    "        df.write.jdbc(url=url, table=table, mode='append', properties=properties)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a79ef36e35aaad83"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|skills                                                                                                                                                                                                                                                                                                                                                                               |\n",
      "+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|Visual Studio; JavaServer Faces (JSF); Primefaces; Hibernate; MongoDB; TestNG; JavaServer Pages (JSP); Netbeans Platform; Tomcat; Java Database Connectivity (JDBC); Java Swing; Enterprise JavaBeans (EJB); Apache Struts; Apache Maven; JSP Standard Tag Library; visual cafe; Visual J++; JavaBeans; Java RMI; Java AWT; Spring Framework; BlazeDS; Junit; Eclipse IDE; JFreeChart|\n",
      "|NULL                                                                                                                                                                                                                                                                                                                                                                                 |\n",
      "|NULL                                                                                                                                                                                                                                                                                                                                                                                 |\n",
      "|NULL                                                                                                                                                                                                                                                                                                                                                                                 |\n",
      "|NULL                                                                                                                                                                                                                                                                                                                                                                                 |\n",
      "|NULL                                                                                                                                                                                                                                                                                                                                                                                 |\n",
      "|NULL                                                                                                                                                                                                                                                                                                                                                                                 |\n",
      "| S3                                                                                                                                                                                                                                                                                                                                                                                  |\n",
      "|NULL                                                                                                                                                                                                                                                                                                                                                                                 |\n",
      "|NULL                                                                                                                                                                                                                                                                                                                                                                                 |\n",
      "+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "hackathon_data.select(\"skills\").show(10,False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-12T11:13:36.243434Z",
     "start_time": "2023-10-12T11:13:35.394389Z"
    }
   },
   "id": "e07c50811ea490a1"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|skills                                                                                                                                                                                                                                                                                                                                                                                                         |soft_skills                                                                                                                                               |\n",
      "+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|[Visual Studio,  JavaServer Faces (JSF),  Primefaces,  Hibernate,  MongoDB,  TestNG,  JavaServer Pages (JSP),  Netbeans Platform,  Tomcat,  Java Database Connectivity (JDBC),  Java Swing,  Enterprise JavaBeans (EJB),  Apache Struts,  Apache Maven,  JSP Standard Tag Library,  visual cafe,  Visual J++,  JavaBeans,  Java RMI,  Java AWT,  Spring Framework,  BlazeDS,  Junit,  Eclipse IDE,  JFreeChart]|[Problem Solving,  Innovative,  Agility,  Creativity,  Cognitive Flexibility,  Analytical,  Ideation,  Supportive,  Business Acumen,  Quality Orientation]|\n",
      "|NULL                                                                                                                                                                                                                                                                                                                                                                                                           |NULL                                                                                                                                                      |\n",
      "|NULL                                                                                                                                                                                                                                                                                                                                                                                                           |NULL                                                                                                                                                      |\n",
      "|NULL                                                                                                                                                                                                                                                                                                                                                                                                           |NULL                                                                                                                                                      |\n",
      "|NULL                                                                                                                                                                                                                                                                                                                                                                                                           |NULL                                                                                                                                                      |\n",
      "|NULL                                                                                                                                                                                                                                                                                                                                                                                                           |NULL                                                                                                                                                      |\n",
      "|NULL                                                                                                                                                                                                                                                                                                                                                                                                           |NULL                                                                                                                                                      |\n",
      "|[ S3]                                                                                                                                                                                                                                                                                                                                                                                                          |[ EC2</strong></li>]                                                                                                                                      |\n",
      "|NULL                                                                                                                                                                                                                                                                                                                                                                                                           |NULL                                                                                                                                                      |\n",
      "|NULL                                                                                                                                                                                                                                                                                                                                                                                                           |NULL                                                                                                                                                      |\n",
      "|NULL                                                                                                                                                                                                                                                                                                                                                                                                           |NULL                                                                                                                                                      |\n",
      "|NULL                                                                                                                                                                                                                                                                                                                                                                                                           |NULL                                                                                                                                                      |\n",
      "|NULL                                                                                                                                                                                                                                                                                                                                                                                                           |NULL                                                                                                                                                      |\n",
      "|NULL                                                                                                                                                                                                                                                                                                                                                                                                           |NULL                                                                                                                                                      |\n",
      "|NULL                                                                                                                                                                                                                                                                                                                                                                                                           |NULL                                                                                                                                                      |\n",
      "|NULL                                                                                                                                                                                                                                                                                                                                                                                                           |NULL                                                                                                                                                      |\n",
      "|NULL                                                                                                                                                                                                                                                                                                                                                                                                           |NULL                                                                                                                                                      |\n",
      "|NULL                                                                                                                                                                                                                                                                                                                                                                                                           |NULL                                                                                                                                                      |\n",
      "|NULL                                                                                                                                                                                                                                                                                                                                                                                                           |NULL                                                                                                                                                      |\n",
      "|NULL                                                                                                                                                                                                                                                                                                                                                                                                           |NULL                                                                                                                                                      |\n",
      "|NULL                                                                                                                                                                                                                                                                                                                                                                                                           |NULL                                                                                                                                                      |\n",
      "|[EGP]                                                                                                                                                                                                                                                                                                                                                                                                          |[Egypt Pound]                                                                                                                                             |\n",
      "|[Visual Studio,  JavaServer Faces (JSF),  Primefaces,  Hibernate,  MongoDB,  TestNG,  JavaServer Pages (JSP),  Netbeans Platform,  Tomcat,  Java Database Connectivity (JDBC),  Java Swing,  Enterprise JavaBeans (EJB),  Apache Struts,  Apache Maven,  JSP Standard Tag Library,  visual cafe,  Visual J++,  JavaBeans,  Java RMI,  Java AWT,  Spring Framework,  BlazeDS,  Junit,  Eclipse IDE,  JFreeChart]|[Problem Solving,  Innovative,  Agility,  Creativity,  Cognitive Flexibility,  Analytical,  Ideation,  Supportive,  Business Acumen,  Quality Orientation]|\n",
      "|NULL                                                                                                                                                                                                                                                                                                                                                                                                           |NULL                                                                                                                                                      |\n",
      "|NULL                                                                                                                                                                                                                                                                                                                                                                                                           |NULL                                                                                                                                                      |\n",
      "|NULL                                                                                                                                                                                                                                                                                                                                                                                                           |NULL                                                                                                                                                      |\n",
      "|NULL                                                                                                                                                                                                                                                                                                                                                                                                           |NULL                                                                                                                                                      |\n",
      "|NULL                                                                                                                                                                                                                                                                                                                                                                                                           |NULL                                                                                                                                                      |\n",
      "|NULL                                                                                                                                                                                                                                                                                                                                                                                                           |NULL                                                                                                                                                      |\n",
      "|[ S3]                                                                                                                                                                                                                                                                                                                                                                                                          |[ EC2</strong></li>]                                                                                                                                      |\n",
      "|NULL                                                                                                                                                                                                                                                                                                                                                                                                           |NULL                                                                                                                                                      |\n",
      "|NULL                                                                                                                                                                                                                                                                                                                                                                                                           |NULL                                                                                                                                                      |\n",
      "|NULL                                                                                                                                                                                                                                                                                                                                                                                                           |NULL                                                                                                                                                      |\n",
      "|NULL                                                                                                                                                                                                                                                                                                                                                                                                           |NULL                                                                                                                                                      |\n",
      "|NULL                                                                                                                                                                                                                                                                                                                                                                                                           |NULL                                                                                                                                                      |\n",
      "|NULL                                                                                                                                                                                                                                                                                                                                                                                                           |NULL                                                                                                                                                      |\n",
      "|NULL                                                                                                                                                                                                                                                                                                                                                                                                           |NULL                                                                                                                                                      |\n",
      "|NULL                                                                                                                                                                                                                                                                                                                                                                                                           |NULL                                                                                                                                                      |\n",
      "|NULL                                                                                                                                                                                                                                                                                                                                                                                                           |NULL                                                                                                                                                      |\n",
      "|NULL                                                                                                                                                                                                                                                                                                                                                                                                           |NULL                                                                                                                                                      |\n",
      "|NULL                                                                                                                                                                                                                                                                                                                                                                                                           |NULL                                                                                                                                                      |\n",
      "|NULL                                                                                                                                                                                                                                                                                                                                                                                                           |NULL                                                                                                                                                      |\n",
      "|NULL                                                                                                                                                                                                                                                                                                                                                                                                           |NULL                                                                                                                                                      |\n",
      "|[EGP]                                                                                                                                                                                                                                                                                                                                                                                                          |[Egypt Pound]                                                                                                                                             |\n",
      "|[Visual Studio,  JavaServer Faces (JSF),  Primefaces,  Hibernate,  MongoDB,  TestNG,  JavaServer Pages (JSP),  Netbeans Platform,  Tomcat,  Java Database Connectivity (JDBC),  Java Swing,  Enterprise JavaBeans (EJB),  Apache Struts,  Apache Maven,  JSP Standard Tag Library,  visual cafe,  Visual J++,  JavaBeans,  Java RMI,  Java AWT,  Spring Framework,  BlazeDS,  Junit,  Eclipse IDE,  JFreeChart]|[Problem Solving,  Innovative,  Agility,  Creativity,  Cognitive Flexibility,  Analytical,  Ideation,  Supportive,  Business Acumen,  Quality Orientation]|\n",
      "|NULL                                                                                                                                                                                                                                                                                                                                                                                                           |NULL                                                                                                                                                      |\n",
      "|NULL                                                                                                                                                                                                                                                                                                                                                                                                           |NULL                                                                                                                                                      |\n",
      "|NULL                                                                                                                                                                                                                                                                                                                                                                                                           |NULL                                                                                                                                                      |\n",
      "|NULL                                                                                                                                                                                                                                                                                                                                                                                                           |NULL                                                                                                                                                      |\n",
      "|NULL                                                                                                                                                                                                                                                                                                                                                                                                           |NULL                                                                                                                                                      |\n",
      "+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "import pyspark.sql.functions as f\n",
    "hackathon_data.withColumn(\"skills\", f.split(\"skills\",\";\")).withColumn(\"soft_skills\", f.split(\"soft_skills\",\";\")).select(\"skills\",\"soft_skills\").show(50,False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-12T11:15:39.808158Z",
     "start_time": "2023-10-12T11:15:39.012089Z"
    }
   },
   "id": "f11a5461981fe721"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "hackathon_data_modified = hackathon_data.withColumn(\"skills\", f.split(\"skills\",\";\")).withColumn(\"soft_skills\", f.split(\"soft_skills\",\";\"))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-12T11:15:59.957119Z",
     "start_time": "2023-10-12T11:15:59.864453Z"
    }
   },
   "id": "eae421daf978586e"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/10/12 16:46:30 WARN MemoryManager: Total allocation exceeds 95.00% (906,992,014 bytes) of heap memory\n",
      "Scaling row group sizes to 96.54% for 7 writers\n",
      "23/10/12 16:46:30 WARN MemoryManager: Total allocation exceeds 95.00% (906,992,014 bytes) of heap memory\n",
      "Scaling row group sizes to 84.47% for 8 writers\n",
      "23/10/12 16:46:30 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , job_role, job_description, skills, soft_skills, responsibility, location_name, talent_cost, currency_code, currency, experience, experience_range, ready_for_application\n",
      " Schema: _c0, job_role, job_description, skills, soft_skills, responsibility, location_name, talent_cost, currency_code, currency, experience, experience_range, ready_for_application\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///Users/eashvrudhula/PycharmProjects/Hackathon3/PostgresData/hackathon_data.csv\n",
      "23/10/12 16:47:00 WARN MemoryManager: Total allocation exceeds 95.00% (906,992,014 bytes) of heap memory\n",
      "Scaling row group sizes to 96.54% for 7 writers\n",
      "23/10/12 16:47:01 WARN MemoryManager: Total allocation exceeds 95.00% (906,992,014 bytes) of heap memory\n",
      "Scaling row group sizes to 96.54% for 7 writers\n",
      "23/10/12 16:47:01 WARN MemoryManager: Total allocation exceeds 95.00% (906,992,014 bytes) of heap memory\n",
      "Scaling row group sizes to 84.47% for 8 writers\n",
      "23/10/12 16:47:27 WARN MemoryManager: Total allocation exceeds 95.00% (906,992,014 bytes) of heap memory\n",
      "Scaling row group sizes to 96.54% for 7 writers\n",
      "23/10/12 16:47:29 WARN MemoryManager: Total allocation exceeds 95.00% (906,992,014 bytes) of heap memory\n",
      "Scaling row group sizes to 96.54% for 7 writers\n",
      "23/10/12 16:47:29 WARN MemoryManager: Total allocation exceeds 95.00% (906,992,014 bytes) of heap memory\n",
      "Scaling row group sizes to 84.47% for 8 writers\n",
      "23/10/12 16:47:53 WARN MemoryManager: Total allocation exceeds 95.00% (906,992,014 bytes) of heap memory\n",
      "Scaling row group sizes to 96.54% for 7 writers\n",
      "23/10/12 16:47:54 WARN MemoryManager: Total allocation exceeds 95.00% (906,992,014 bytes) of heap memory\n",
      "Scaling row group sizes to 96.54% for 7 writers\n",
      "23/10/12 16:47:54 WARN MemoryManager: Total allocation exceeds 95.00% (906,992,014 bytes) of heap memory\n",
      "Scaling row group sizes to 84.47% for 8 writers\n",
      "23/10/12 16:47:54 WARN MemoryManager: Total allocation exceeds 95.00% (906,992,014 bytes) of heap memory\n",
      "Scaling row group sizes to 96.54% for 7 writers\n",
      "23/10/12 16:47:54 WARN MemoryManager: Total allocation exceeds 95.00% (906,992,014 bytes) of heap memory\n",
      "Scaling row group sizes to 84.47% for 8 writers\n",
      "23/10/12 16:48:17 WARN MemoryManager: Total allocation exceeds 95.00% (906,992,014 bytes) of heap memory\n",
      "Scaling row group sizes to 96.54% for 7 writers\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "hackathon_data_modified.write.parquet(\"/Users/eashvrudhula/PycharmProjects/Hackathon3/PostgresData/hackathon_data_modified\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-12T11:18:26.995492Z",
     "start_time": "2023-10-12T11:16:27.405193Z"
    }
   },
   "id": "99ac05813bef678"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi\n"
     ]
    }
   ],
   "source": [
    "print(\"hi\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-12T11:18:51.927087Z",
     "start_time": "2023-10-12T11:18:51.921043Z"
    }
   },
   "id": "510c2aa743c748a5"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "modded = spark.read.parquet(\"/Users/eashvrudhula/PycharmProjects/Hackathon3/PostgresData/hackathon_data_modified\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-12T11:49:25.657785Z",
     "start_time": "2023-10-12T11:49:20.724236Z"
    }
   },
   "id": "772151da9e2a6111"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "55d2390ad7029da5"
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "ename": "AnalysisException",
     "evalue": "[UNSUPPORTED_DATA_TYPE_FOR_DATASOURCE] The CSV datasource doesn't support the column `skills` of the type \"ARRAY<STRING>\".",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAnalysisException\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[23], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mmodded\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mwrite\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mformat\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mcsv\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msave\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m/Users/eashvrudhula/PycharmProjects/Hackathon3/PostgresData/hackathon_data_modified_csv\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43mheader\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/Hackathon3/venv/lib/python3.10/site-packages/pyspark/sql/readwriter.py:1463\u001B[0m, in \u001B[0;36mDataFrameWriter.save\u001B[0;34m(self, path, format, mode, partitionBy, **options)\u001B[0m\n\u001B[1;32m   1461\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jwrite\u001B[38;5;241m.\u001B[39msave()\n\u001B[1;32m   1462\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1463\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_jwrite\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msave\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpath\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/Hackathon3/venv/lib/python3.10/site-packages/py4j/java_gateway.py:1322\u001B[0m, in \u001B[0;36mJavaMember.__call__\u001B[0;34m(self, *args)\u001B[0m\n\u001B[1;32m   1316\u001B[0m command \u001B[38;5;241m=\u001B[39m proto\u001B[38;5;241m.\u001B[39mCALL_COMMAND_NAME \u001B[38;5;241m+\u001B[39m\\\n\u001B[1;32m   1317\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcommand_header \u001B[38;5;241m+\u001B[39m\\\n\u001B[1;32m   1318\u001B[0m     args_command \u001B[38;5;241m+\u001B[39m\\\n\u001B[1;32m   1319\u001B[0m     proto\u001B[38;5;241m.\u001B[39mEND_COMMAND_PART\n\u001B[1;32m   1321\u001B[0m answer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgateway_client\u001B[38;5;241m.\u001B[39msend_command(command)\n\u001B[0;32m-> 1322\u001B[0m return_value \u001B[38;5;241m=\u001B[39m \u001B[43mget_return_value\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1323\u001B[0m \u001B[43m    \u001B[49m\u001B[43manswer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgateway_client\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtarget_id\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1325\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m temp_arg \u001B[38;5;129;01min\u001B[39;00m temp_args:\n\u001B[1;32m   1326\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(temp_arg, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m_detach\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n",
      "File \u001B[0;32m~/PycharmProjects/Hackathon3/venv/lib/python3.10/site-packages/pyspark/errors/exceptions/captured.py:185\u001B[0m, in \u001B[0;36mcapture_sql_exception.<locals>.deco\u001B[0;34m(*a, **kw)\u001B[0m\n\u001B[1;32m    181\u001B[0m converted \u001B[38;5;241m=\u001B[39m convert_exception(e\u001B[38;5;241m.\u001B[39mjava_exception)\n\u001B[1;32m    182\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(converted, UnknownException):\n\u001B[1;32m    183\u001B[0m     \u001B[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001B[39;00m\n\u001B[1;32m    184\u001B[0m     \u001B[38;5;66;03m# JVM exception message.\u001B[39;00m\n\u001B[0;32m--> 185\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m converted \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    186\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    187\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m\n",
      "\u001B[0;31mAnalysisException\u001B[0m: [UNSUPPORTED_DATA_TYPE_FOR_DATASOURCE] The CSV datasource doesn't support the column `skills` of the type \"ARRAY<STRING>\"."
     ]
    }
   ],
   "source": [
    "modded.write.format(\"csv\").save(\"/Users/eashvrudhula/PycharmProjects/Hackathon3/PostgresData/hackathon_data_modified_csv\",header=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-12T11:31:05.757730Z",
     "start_time": "2023-10-12T11:31:05.458497Z"
    }
   },
   "id": "9df85ee652600215"
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": "28612886"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modded.count()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-12T11:19:44.027079Z",
     "start_time": "2023-10-12T11:19:42.012275Z"
    }
   },
   "id": "dc45475e0d358ea3"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "28612886"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dab5aeccc56efd1c"
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": "28612886"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hackathon_data.count()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-12T11:20:04.436482Z",
     "start_time": "2023-10-12T11:19:57.865199Z"
    }
   },
   "id": "3657580f4a6be1b1"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "url = \"localhost:5432/postgres?user=postgres&password=$Eash1312#\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-12T11:34:44.328810Z",
     "start_time": "2023-10-12T11:34:44.317214Z"
    }
   },
   "id": "83dbdb8f7a3b352"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "17a7faf1b8583b53"
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'url' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[18], line 6\u001B[0m\n\u001B[1;32m      1\u001B[0m properties \u001B[38;5;241m=\u001B[39m {\n\u001B[1;32m      2\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124muser\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpostgres\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m      3\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpassword\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m$Eash1312#\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m      4\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdriver\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124morg.postgresql.Driver\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m      5\u001B[0m }\n\u001B[0;32m----> 6\u001B[0m modded\u001B[38;5;241m.\u001B[39mwrite\u001B[38;5;241m.\u001B[39mjdbc(url\u001B[38;5;241m=\u001B[39m\u001B[43murl\u001B[49m, table\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mjob_data\u001B[39m\u001B[38;5;124m\"\u001B[39m, mode\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mappend\u001B[39m\u001B[38;5;124m'\u001B[39m,properties\u001B[38;5;241m=\u001B[39mproperties)\n",
      "\u001B[0;31mNameError\u001B[0m: name 'url' is not defined"
     ]
    }
   ],
   "source": [
    "# properties = {\n",
    "#             \"user\": \"postgres\",\n",
    "#             \"password\": \"$Eash1312#\",\n",
    "#             \"driver\": \"org.postgresql.Driver\"\n",
    "# }"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-12T12:10:31.059465Z",
     "start_time": "2023-10-12T12:10:30.887640Z"
    }
   },
   "id": "fe69dfca0ce49f67"
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "properties = {\n",
    "            \"user\": \"postgres\",\n",
    "            \"password\": \"$Eash1312#\",\n",
    "            \"driver\": \"org.postgresql.Driver\"\n",
    "}\n",
    "driver = \"postgresql\"\n",
    "hostname = \"localhost\"\n",
    "port = \"5432\"\n",
    "database = \"postgres\"\n",
    "username = \"postgres\"\n",
    "password = \"$Eash1312#\"\n",
    "url = \"jdbc:{0}://{1}:{2}/{3}?user={4}&password={5}\".format(driver, hostname, port, database, username,\n",
    "                                                                    password)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-12T12:19:07.084481Z",
     "start_time": "2023-10-12T12:19:07.061168Z"
    }
   },
   "id": "bfbd2024497d7bd2"
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/10/12 17:49:11 ERROR Executor: Exception in task 2.0 in stage 12.0 (TID 40)8]\n",
      "java.sql.BatchUpdateException: Batch entry 0 INSERT INTO job_data (\"job_role\",\"job_description\",\"responsibility\",\"location_name\",\"talent_cost\",\"currency_code\",\"currency\",\"experience\",\"experience_range\",\"ready_for_application\",\"skillset\") VALUES (NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,'{\"soft_skills\": null, \"skills\": null}') was aborted: ERROR: column \"talent_cost\" is of type numeric but expression is of type character varying\n",
      "  Hint: You will need to rewrite or cast the expression.\n",
      "  Position: 214  Call getNextException to see other errors in the batch.\n",
      "\tat org.postgresql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:165)\n",
      "\tat org.postgresql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:880)\n",
      "\tat org.postgresql.jdbc.PgStatement.executeBatch(PgStatement.java:919)\n",
      "\tat org.postgresql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1685)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:746)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:902)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:901)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1036)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1036)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2438)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.postgresql.util.PSQLException: ERROR: column \"talent_cost\" is of type numeric but expression is of type character varying\n",
      "  Hint: You will need to rewrite or cast the expression.\n",
      "  Position: 214\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2713)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2401)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:368)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:327)\n",
      "\tat org.postgresql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:877)\n",
      "\t... 19 more\n",
      "23/10/12 17:49:11 ERROR Executor: Exception in task 3.0 in stage 12.0 (TID 41)\n",
      "java.sql.BatchUpdateException: Batch entry 0 INSERT INTO job_data (\"job_role\",\"job_description\",\"responsibility\",\"location_name\",\"talent_cost\",\"currency_code\",\"currency\",\"experience\",\"experience_range\",\"ready_for_application\",\"skillset\") VALUES (NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,'{\"soft_skills\": null, \"skills\": null}') was aborted: ERROR: column \"talent_cost\" is of type numeric but expression is of type character varying\n",
      "  Hint: You will need to rewrite or cast the expression.\n",
      "  Position: 214  Call getNextException to see other errors in the batch.\n",
      "\tat org.postgresql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:165)\n",
      "\tat org.postgresql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:880)\n",
      "\tat org.postgresql.jdbc.PgStatement.executeBatch(PgStatement.java:919)\n",
      "\tat org.postgresql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1685)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:746)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:902)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:901)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1036)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1036)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2438)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.postgresql.util.PSQLException: ERROR: column \"talent_cost\" is of type numeric but expression is of type character varying\n",
      "  Hint: You will need to rewrite or cast the expression.\n",
      "  Position: 214\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2713)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2401)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:368)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:327)\n",
      "\tat org.postgresql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:877)\n",
      "\t... 19 more\n",
      "23/10/12 17:49:11 ERROR Executor: Exception in task 5.0 in stage 12.0 (TID 43)\n",
      "java.sql.BatchUpdateException: Batch entry 0 INSERT INTO job_data (\"job_role\",\"job_description\",\"responsibility\",\"location_name\",\"talent_cost\",\"currency_code\",\"currency\",\"experience\",\"experience_range\",\"ready_for_application\",\"skillset\") VALUES (NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,'{\"soft_skills\": null, \"skills\": null}') was aborted: ERROR: column \"talent_cost\" is of type numeric but expression is of type character varying\n",
      "  Hint: You will need to rewrite or cast the expression.\n",
      "  Position: 214  Call getNextException to see other errors in the batch.\n",
      "\tat org.postgresql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:165)\n",
      "\tat org.postgresql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:880)\n",
      "\tat org.postgresql.jdbc.PgStatement.executeBatch(PgStatement.java:919)\n",
      "\tat org.postgresql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1685)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:746)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:902)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:901)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1036)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1036)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2438)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.postgresql.util.PSQLException: ERROR: column \"talent_cost\" is of type numeric but expression is of type character varying\n",
      "  Hint: You will need to rewrite or cast the expression.\n",
      "  Position: 214\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2713)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2401)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:368)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:327)\n",
      "\tat org.postgresql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:877)\n",
      "\t... 19 more\n",
      "23/10/12 17:49:11 ERROR Executor: Exception in task 7.0 in stage 12.0 (TID 45)\n",
      "java.sql.BatchUpdateException: Batch entry 0 INSERT INTO job_data (\"job_role\",\"job_description\",\"responsibility\",\"location_name\",\"talent_cost\",\"currency_code\",\"currency\",\"experience\",\"experience_range\",\"ready_for_application\",\"skillset\") VALUES (NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,'{\"soft_skills\": null, \"skills\": null}') was aborted: ERROR: column \"talent_cost\" is of type numeric but expression is of type character varying\n",
      "  Hint: You will need to rewrite or cast the expression.\n",
      "  Position: 214  Call getNextException to see other errors in the batch.\n",
      "\tat org.postgresql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:165)\n",
      "\tat org.postgresql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:880)\n",
      "\tat org.postgresql.jdbc.PgStatement.executeBatch(PgStatement.java:919)\n",
      "\tat org.postgresql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1685)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:746)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:902)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:901)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1036)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1036)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2438)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.postgresql.util.PSQLException: ERROR: column \"talent_cost\" is of type numeric but expression is of type character varying\n",
      "  Hint: You will need to rewrite or cast the expression.\n",
      "  Position: 214\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2713)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2401)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:368)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:327)\n",
      "\tat org.postgresql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:877)\n",
      "\t... 19 more\n",
      "23/10/12 17:49:11 ERROR Executor: Exception in task 6.0 in stage 12.0 (TID 44)\n",
      "java.sql.BatchUpdateException: Batch entry 0 INSERT INTO job_data (\"job_role\",\"job_description\",\"responsibility\",\"location_name\",\"talent_cost\",\"currency_code\",\"currency\",\"experience\",\"experience_range\",\"ready_for_application\",\"skillset\") VALUES (NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,'{\"soft_skills\": null, \"skills\": null}') was aborted: ERROR: column \"talent_cost\" is of type numeric but expression is of type character varying\n",
      "  Hint: You will need to rewrite or cast the expression.\n",
      "  Position: 214  Call getNextException to see other errors in the batch.\n",
      "\tat org.postgresql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:165)\n",
      "\tat org.postgresql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:880)\n",
      "\tat org.postgresql.jdbc.PgStatement.executeBatch(PgStatement.java:919)\n",
      "\tat org.postgresql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1685)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:746)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:902)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:901)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1036)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1036)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2438)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.postgresql.util.PSQLException: ERROR: column \"talent_cost\" is of type numeric but expression is of type character varying\n",
      "  Hint: You will need to rewrite or cast the expression.\n",
      "  Position: 214\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2713)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2401)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:368)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:327)\n",
      "\tat org.postgresql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:877)\n",
      "\t... 19 more\n",
      "23/10/12 17:49:11 ERROR Executor: Exception in task 1.0 in stage 12.0 (TID 39)\n",
      "java.sql.BatchUpdateException: Batch entry 0 INSERT INTO job_data (\"job_role\",\"job_description\",\"responsibility\",\"location_name\",\"talent_cost\",\"currency_code\",\"currency\",\"experience\",\"experience_range\",\"ready_for_application\",\"skillset\") VALUES (NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,'{\"soft_skills\": null, \"skills\": null}') was aborted: ERROR: column \"talent_cost\" is of type numeric but expression is of type character varying\n",
      "  Hint: You will need to rewrite or cast the expression.\n",
      "  Position: 214  Call getNextException to see other errors in the batch.\n",
      "\tat org.postgresql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:165)\n",
      "\tat org.postgresql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:880)\n",
      "\tat org.postgresql.jdbc.PgStatement.executeBatch(PgStatement.java:919)\n",
      "\tat org.postgresql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1685)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:746)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:902)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:901)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1036)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1036)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2438)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.postgresql.util.PSQLException: ERROR: column \"talent_cost\" is of type numeric but expression is of type character varying\n",
      "  Hint: You will need to rewrite or cast the expression.\n",
      "  Position: 214\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2713)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2401)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:368)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:327)\n",
      "\tat org.postgresql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:877)\n",
      "\t... 19 more\n",
      "23/10/12 17:49:11 ERROR Executor: Exception in task 4.0 in stage 12.0 (TID 42)\n",
      "java.sql.BatchUpdateException: Batch entry 0 INSERT INTO job_data (\"job_role\",\"job_description\",\"responsibility\",\"location_name\",\"talent_cost\",\"currency_code\",\"currency\",\"experience\",\"experience_range\",\"ready_for_application\",\"skillset\") VALUES (NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,'{\"soft_skills\": null, \"skills\": null}') was aborted: ERROR: column \"talent_cost\" is of type numeric but expression is of type character varying\n",
      "  Hint: You will need to rewrite or cast the expression.\n",
      "  Position: 214  Call getNextException to see other errors in the batch.\n",
      "\tat org.postgresql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:165)\n",
      "\tat org.postgresql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:880)\n",
      "\tat org.postgresql.jdbc.PgStatement.executeBatch(PgStatement.java:919)\n",
      "\tat org.postgresql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1685)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:746)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:902)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:901)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1036)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1036)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2438)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.postgresql.util.PSQLException: ERROR: column \"talent_cost\" is of type numeric but expression is of type character varying\n",
      "  Hint: You will need to rewrite or cast the expression.\n",
      "  Position: 214\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2713)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2401)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:368)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:327)\n",
      "\tat org.postgresql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:877)\n",
      "\t... 19 more\n",
      "23/10/12 17:49:11 ERROR Executor: Exception in task 0.0 in stage 12.0 (TID 38)\n",
      "java.sql.BatchUpdateException: Batch entry 0 INSERT INTO job_data (\"job_role\",\"job_description\",\"responsibility\",\"location_name\",\"talent_cost\",\"currency_code\",\"currency\",\"experience\",\"experience_range\",\"ready_for_application\",\"skillset\") VALUES (NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,'{\"soft_skills\": null, \"skills\": null}') was aborted: ERROR: column \"talent_cost\" is of type numeric but expression is of type character varying\n",
      "  Hint: You will need to rewrite or cast the expression.\n",
      "  Position: 214  Call getNextException to see other errors in the batch.\n",
      "\tat org.postgresql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:165)\n",
      "\tat org.postgresql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:880)\n",
      "\tat org.postgresql.jdbc.PgStatement.executeBatch(PgStatement.java:919)\n",
      "\tat org.postgresql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1685)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:746)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:902)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:901)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1036)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1036)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2438)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.postgresql.util.PSQLException: ERROR: column \"talent_cost\" is of type numeric but expression is of type character varying\n",
      "  Hint: You will need to rewrite or cast the expression.\n",
      "  Position: 214\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2713)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2401)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:368)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:327)\n",
      "\tat org.postgresql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:877)\n",
      "\t... 19 more\n",
      "23/10/12 17:49:11 WARN TaskSetManager: Lost task 4.0 in stage 12.0 (TID 42) (192.168.2.137 executor driver): java.sql.BatchUpdateException: Batch entry 0 INSERT INTO job_data (\"job_role\",\"job_description\",\"responsibility\",\"location_name\",\"talent_cost\",\"currency_code\",\"currency\",\"experience\",\"experience_range\",\"ready_for_application\",\"skillset\") VALUES (NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,'{\"soft_skills\": null, \"skills\": null}') was aborted: ERROR: column \"talent_cost\" is of type numeric but expression is of type character varying\n",
      "  Hint: You will need to rewrite or cast the expression.\n",
      "  Position: 214  Call getNextException to see other errors in the batch.\n",
      "\tat org.postgresql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:165)\n",
      "\tat org.postgresql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:880)\n",
      "\tat org.postgresql.jdbc.PgStatement.executeBatch(PgStatement.java:919)\n",
      "\tat org.postgresql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1685)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:746)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:902)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:901)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1036)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1036)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2438)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.postgresql.util.PSQLException: ERROR: column \"talent_cost\" is of type numeric but expression is of type character varying\n",
      "  Hint: You will need to rewrite or cast the expression.\n",
      "  Position: 214\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2713)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2401)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:368)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:327)\n",
      "\tat org.postgresql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:877)\n",
      "\t... 19 more\n",
      "\n",
      "23/10/12 17:49:11 ERROR TaskSetManager: Task 4 in stage 12.0 failed 1 times; aborting job\n",
      "23/10/12 17:49:11 WARN TaskSetManager: Lost task 8.0 in stage 12.0 (TID 46) (192.168.2.137 executor driver): TaskKilled (Stage cancelled: Job aborted due to stage failure: Task 4 in stage 12.0 failed 1 times, most recent failure: Lost task 4.0 in stage 12.0 (TID 42) (192.168.2.137 executor driver): java.sql.BatchUpdateException: Batch entry 0 INSERT INTO job_data (\"job_role\",\"job_description\",\"responsibility\",\"location_name\",\"talent_cost\",\"currency_code\",\"currency\",\"experience\",\"experience_range\",\"ready_for_application\",\"skillset\") VALUES (NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,'{\"soft_skills\": null, \"skills\": null}') was aborted: ERROR: column \"talent_cost\" is of type numeric but expression is of type character varying\n",
      "  Hint: You will need to rewrite or cast the expression.\n",
      "  Position: 214  Call getNextException to see other errors in the batch.\n",
      "\tat org.postgresql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:165)\n",
      "\tat org.postgresql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:880)\n",
      "\tat org.postgresql.jdbc.PgStatement.executeBatch(PgStatement.java:919)\n",
      "\tat org.postgresql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1685)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:746)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:902)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:901)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1036)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1036)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2438)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.postgresql.util.PSQLException: ERROR: column \"talent_cost\" is of type numeric but expression is of type character varying\n",
      "  Hint: You will need to rewrite or cast the expression.\n",
      "  Position: 214\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2713)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2401)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:368)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:327)\n",
      "\tat org.postgresql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:877)\n",
      "\t... 19 more\n",
      "\n",
      "Driver stacktrace:)\n"
     ]
    },
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling o243.jdbc.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 4 in stage 12.0 failed 1 times, most recent failure: Lost task 4.0 in stage 12.0 (TID 42) (192.168.2.137 executor driver): java.sql.BatchUpdateException: Batch entry 0 INSERT INTO job_data (\"job_role\",\"job_description\",\"responsibility\",\"location_name\",\"talent_cost\",\"currency_code\",\"currency\",\"experience\",\"experience_range\",\"ready_for_application\",\"skillset\") VALUES (NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,'{\"soft_skills\": null, \"skills\": null}') was aborted: ERROR: column \"talent_cost\" is of type numeric but expression is of type character varying\n  Hint: You will need to rewrite or cast the expression.\n  Position: 214  Call getNextException to see other errors in the batch.\n\tat org.postgresql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:165)\n\tat org.postgresql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:880)\n\tat org.postgresql.jdbc.PgStatement.executeBatch(PgStatement.java:919)\n\tat org.postgresql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1685)\n\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:746)\n\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:902)\n\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:901)\n\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1036)\n\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1036)\n\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2438)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:750)\nCaused by: org.postgresql.util.PSQLException: ERROR: column \"talent_cost\" is of type numeric but expression is of type character varying\n  Hint: You will need to rewrite or cast the expression.\n  Position: 214\n\tat org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2713)\n\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2401)\n\tat org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:368)\n\tat org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:327)\n\tat org.postgresql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:877)\n\t... 19 more\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2844)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2780)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2779)\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2779)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1242)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1242)\n\tat scala.Option.foreach(Option.scala:407)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1242)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:3048)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2982)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2971)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:984)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2398)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2419)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2438)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2463)\n\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$1(RDD.scala:1036)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:407)\n\tat org.apache.spark.rdd.RDD.foreachPartition(RDD.scala:1034)\n\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.saveTable(JdbcUtils.scala:901)\n\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcRelationProvider.createRelation(JdbcRelationProvider.scala:70)\n\tat org.apache.spark.sql.execution.datasources.SaveIntoDataSourceCommand.run(SaveIntoDataSourceCommand.scala:48)\n\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult$lzycompute(commands.scala:75)\n\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult(commands.scala:73)\n\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.executeCollect(commands.scala:84)\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.$anonfun$applyOrElse$1(QueryExecution.scala:107)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:107)\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:98)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:461)\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:461)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:32)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:437)\n\tat org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:98)\n\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:85)\n\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:83)\n\tat org.apache.spark.sql.execution.QueryExecution.assertCommandExecuted(QueryExecution.scala:142)\n\tat org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:859)\n\tat org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:388)\n\tat org.apache.spark.sql.DataFrameWriter.saveInternal(DataFrameWriter.scala:361)\n\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:248)\n\tat org.apache.spark.sql.DataFrameWriter.jdbc(DataFrameWriter.scala:756)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n\tat java.lang.Thread.run(Thread.java:750)\nCaused by: java.sql.BatchUpdateException: Batch entry 0 INSERT INTO job_data (\"job_role\",\"job_description\",\"responsibility\",\"location_name\",\"talent_cost\",\"currency_code\",\"currency\",\"experience\",\"experience_range\",\"ready_for_application\",\"skillset\") VALUES (NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,'{\"soft_skills\": null, \"skills\": null}') was aborted: ERROR: column \"talent_cost\" is of type numeric but expression is of type character varying\n  Hint: You will need to rewrite or cast the expression.\n  Position: 214  Call getNextException to see other errors in the batch.\n\tat org.postgresql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:165)\n\tat org.postgresql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:880)\n\tat org.postgresql.jdbc.PgStatement.executeBatch(PgStatement.java:919)\n\tat org.postgresql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1685)\n\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:746)\n\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:902)\n\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:901)\n\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1036)\n\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1036)\n\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2438)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\t... 1 more\nCaused by: org.postgresql.util.PSQLException: ERROR: column \"talent_cost\" is of type numeric but expression is of type character varying\n  Hint: You will need to rewrite or cast the expression.\n  Position: 214\n\tat org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2713)\n\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2401)\n\tat org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:368)\n\tat org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:327)\n\tat org.postgresql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:877)\n\t... 19 more\n",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mPy4JJavaError\u001B[0m                             Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[23], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mskillset\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdrop\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m_c0\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mwrite\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mjdbc\u001B[49m\u001B[43m(\u001B[49m\u001B[43murl\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43murl\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mjob_data\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmode\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mappend\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43mproperties\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mproperties\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/Hackathon3/venv/lib/python3.10/site-packages/pyspark/sql/readwriter.py:1984\u001B[0m, in \u001B[0;36mDataFrameWriter.jdbc\u001B[0;34m(self, url, table, mode, properties)\u001B[0m\n\u001B[1;32m   1982\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m k \u001B[38;5;129;01min\u001B[39;00m properties:\n\u001B[1;32m   1983\u001B[0m     jprop\u001B[38;5;241m.\u001B[39msetProperty(k, properties[k])\n\u001B[0;32m-> 1984\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmode\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmode\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_jwrite\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mjdbc\u001B[49m\u001B[43m(\u001B[49m\u001B[43murl\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtable\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mjprop\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/Hackathon3/venv/lib/python3.10/site-packages/py4j/java_gateway.py:1322\u001B[0m, in \u001B[0;36mJavaMember.__call__\u001B[0;34m(self, *args)\u001B[0m\n\u001B[1;32m   1316\u001B[0m command \u001B[38;5;241m=\u001B[39m proto\u001B[38;5;241m.\u001B[39mCALL_COMMAND_NAME \u001B[38;5;241m+\u001B[39m\\\n\u001B[1;32m   1317\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcommand_header \u001B[38;5;241m+\u001B[39m\\\n\u001B[1;32m   1318\u001B[0m     args_command \u001B[38;5;241m+\u001B[39m\\\n\u001B[1;32m   1319\u001B[0m     proto\u001B[38;5;241m.\u001B[39mEND_COMMAND_PART\n\u001B[1;32m   1321\u001B[0m answer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgateway_client\u001B[38;5;241m.\u001B[39msend_command(command)\n\u001B[0;32m-> 1322\u001B[0m return_value \u001B[38;5;241m=\u001B[39m \u001B[43mget_return_value\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1323\u001B[0m \u001B[43m    \u001B[49m\u001B[43manswer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgateway_client\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtarget_id\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1325\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m temp_arg \u001B[38;5;129;01min\u001B[39;00m temp_args:\n\u001B[1;32m   1326\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(temp_arg, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m_detach\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n",
      "File \u001B[0;32m~/PycharmProjects/Hackathon3/venv/lib/python3.10/site-packages/pyspark/errors/exceptions/captured.py:179\u001B[0m, in \u001B[0;36mcapture_sql_exception.<locals>.deco\u001B[0;34m(*a, **kw)\u001B[0m\n\u001B[1;32m    177\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mdeco\u001B[39m(\u001B[38;5;241m*\u001B[39ma: Any, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkw: Any) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Any:\n\u001B[1;32m    178\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 179\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mf\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43ma\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkw\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    180\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m Py4JJavaError \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    181\u001B[0m         converted \u001B[38;5;241m=\u001B[39m convert_exception(e\u001B[38;5;241m.\u001B[39mjava_exception)\n",
      "File \u001B[0;32m~/PycharmProjects/Hackathon3/venv/lib/python3.10/site-packages/py4j/protocol.py:326\u001B[0m, in \u001B[0;36mget_return_value\u001B[0;34m(answer, gateway_client, target_id, name)\u001B[0m\n\u001B[1;32m    324\u001B[0m value \u001B[38;5;241m=\u001B[39m OUTPUT_CONVERTER[\u001B[38;5;28mtype\u001B[39m](answer[\u001B[38;5;241m2\u001B[39m:], gateway_client)\n\u001B[1;32m    325\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m answer[\u001B[38;5;241m1\u001B[39m] \u001B[38;5;241m==\u001B[39m REFERENCE_TYPE:\n\u001B[0;32m--> 326\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m Py4JJavaError(\n\u001B[1;32m    327\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mAn error occurred while calling \u001B[39m\u001B[38;5;132;01m{0}\u001B[39;00m\u001B[38;5;132;01m{1}\u001B[39;00m\u001B[38;5;132;01m{2}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39m\n\u001B[1;32m    328\u001B[0m         \u001B[38;5;28mformat\u001B[39m(target_id, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m, name), value)\n\u001B[1;32m    329\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    330\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m Py4JError(\n\u001B[1;32m    331\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mAn error occurred while calling \u001B[39m\u001B[38;5;132;01m{0}\u001B[39;00m\u001B[38;5;132;01m{1}\u001B[39;00m\u001B[38;5;132;01m{2}\u001B[39;00m\u001B[38;5;124m. Trace:\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;132;01m{3}\u001B[39;00m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39m\n\u001B[1;32m    332\u001B[0m         \u001B[38;5;28mformat\u001B[39m(target_id, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m, name, value))\n",
      "\u001B[0;31mPy4JJavaError\u001B[0m: An error occurred while calling o243.jdbc.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 4 in stage 12.0 failed 1 times, most recent failure: Lost task 4.0 in stage 12.0 (TID 42) (192.168.2.137 executor driver): java.sql.BatchUpdateException: Batch entry 0 INSERT INTO job_data (\"job_role\",\"job_description\",\"responsibility\",\"location_name\",\"talent_cost\",\"currency_code\",\"currency\",\"experience\",\"experience_range\",\"ready_for_application\",\"skillset\") VALUES (NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,'{\"soft_skills\": null, \"skills\": null}') was aborted: ERROR: column \"talent_cost\" is of type numeric but expression is of type character varying\n  Hint: You will need to rewrite or cast the expression.\n  Position: 214  Call getNextException to see other errors in the batch.\n\tat org.postgresql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:165)\n\tat org.postgresql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:880)\n\tat org.postgresql.jdbc.PgStatement.executeBatch(PgStatement.java:919)\n\tat org.postgresql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1685)\n\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:746)\n\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:902)\n\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:901)\n\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1036)\n\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1036)\n\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2438)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:750)\nCaused by: org.postgresql.util.PSQLException: ERROR: column \"talent_cost\" is of type numeric but expression is of type character varying\n  Hint: You will need to rewrite or cast the expression.\n  Position: 214\n\tat org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2713)\n\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2401)\n\tat org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:368)\n\tat org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:327)\n\tat org.postgresql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:877)\n\t... 19 more\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2844)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2780)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2779)\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2779)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1242)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1242)\n\tat scala.Option.foreach(Option.scala:407)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1242)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:3048)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2982)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2971)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:984)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2398)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2419)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2438)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2463)\n\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$1(RDD.scala:1036)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:407)\n\tat org.apache.spark.rdd.RDD.foreachPartition(RDD.scala:1034)\n\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.saveTable(JdbcUtils.scala:901)\n\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcRelationProvider.createRelation(JdbcRelationProvider.scala:70)\n\tat org.apache.spark.sql.execution.datasources.SaveIntoDataSourceCommand.run(SaveIntoDataSourceCommand.scala:48)\n\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult$lzycompute(commands.scala:75)\n\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult(commands.scala:73)\n\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.executeCollect(commands.scala:84)\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.$anonfun$applyOrElse$1(QueryExecution.scala:107)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:107)\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:98)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:461)\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:461)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:32)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:437)\n\tat org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:98)\n\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:85)\n\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:83)\n\tat org.apache.spark.sql.execution.QueryExecution.assertCommandExecuted(QueryExecution.scala:142)\n\tat org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:859)\n\tat org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:388)\n\tat org.apache.spark.sql.DataFrameWriter.saveInternal(DataFrameWriter.scala:361)\n\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:248)\n\tat org.apache.spark.sql.DataFrameWriter.jdbc(DataFrameWriter.scala:756)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n\tat java.lang.Thread.run(Thread.java:750)\nCaused by: java.sql.BatchUpdateException: Batch entry 0 INSERT INTO job_data (\"job_role\",\"job_description\",\"responsibility\",\"location_name\",\"talent_cost\",\"currency_code\",\"currency\",\"experience\",\"experience_range\",\"ready_for_application\",\"skillset\") VALUES (NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,'{\"soft_skills\": null, \"skills\": null}') was aborted: ERROR: column \"talent_cost\" is of type numeric but expression is of type character varying\n  Hint: You will need to rewrite or cast the expression.\n  Position: 214  Call getNextException to see other errors in the batch.\n\tat org.postgresql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:165)\n\tat org.postgresql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:880)\n\tat org.postgresql.jdbc.PgStatement.executeBatch(PgStatement.java:919)\n\tat org.postgresql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1685)\n\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:746)\n\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:902)\n\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:901)\n\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1036)\n\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1036)\n\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2438)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\t... 1 more\nCaused by: org.postgresql.util.PSQLException: ERROR: column \"talent_cost\" is of type numeric but expression is of type character varying\n  Hint: You will need to rewrite or cast the expression.\n  Position: 214\n\tat org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2713)\n\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2401)\n\tat org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:368)\n\tat org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:327)\n\tat org.postgresql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:877)\n\t... 19 more\n"
     ]
    }
   ],
   "source": [
    "skillset.drop(\"_c0\").write.jdbc(url=url, table=\"job_data\", mode='append',properties=properties)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-12T12:19:12.584345Z",
     "start_time": "2023-10-12T12:19:08.727050Z"
    }
   },
   "id": "661859ad988c485a"
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'driver' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[17], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[43mdriver\u001B[49m)\n",
      "\u001B[0;31mNameError\u001B[0m: name 'driver' is not defined"
     ]
    }
   ],
   "source": [
    "print(driver)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-12T12:10:10.187396Z",
     "start_time": "2023-10-12T12:10:10.127318Z"
    }
   },
   "id": "47aa8a13ccbcc843"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/10/12 17:17:11 ERROR Executor: Exception in task 2.0 in stage 1.0 (TID 3)/ 8]\n",
      "java.lang.OutOfMemoryError: Java heap space\n",
      "\tat java.nio.HeapByteBuffer.<init>(HeapByteBuffer.java:57)\n",
      "\tat java.nio.ByteBuffer.allocate(ByteBuffer.java:335)\n",
      "\tat org.apache.spark.serializer.SerializerHelper$.$anonfun$serializeToChunkedBuffer$1(SerializerHelper.scala:40)\n",
      "\tat org.apache.spark.serializer.SerializerHelper$.$anonfun$serializeToChunkedBuffer$1$adapted(SerializerHelper.scala:40)\n",
      "\tat org.apache.spark.serializer.SerializerHelper$$$Lambda$1644/39752490.apply(Unknown Source)\n",
      "\tat org.apache.spark.util.io.ChunkedByteBufferOutputStream.allocateNewChunkIfNeeded(ChunkedByteBufferOutputStream.scala:87)\n",
      "\tat org.apache.spark.util.io.ChunkedByteBufferOutputStream.write(ChunkedByteBufferOutputStream.scala:75)\n",
      "\tat java.io.ObjectOutputStream$BlockDataOutputStream.write(ObjectOutputStream.java:1853)\n",
      "\tat java.io.ObjectOutputStream.write(ObjectOutputStream.java:709)\n",
      "\tat org.apache.spark.util.Utils$.$anonfun$writeByteBuffer$1(Utils.scala:209)\n",
      "\tat org.apache.spark.util.Utils$.$anonfun$writeByteBuffer$1$adapted(Utils.scala:209)\n",
      "\tat org.apache.spark.util.Utils$$$Lambda$1651/1509052106.apply(Unknown Source)\n",
      "\tat org.apache.spark.util.Utils$.writeByteBufferImpl(Utils.scala:187)\n",
      "\tat org.apache.spark.util.Utils$.writeByteBuffer(Utils.scala:209)\n",
      "\tat org.apache.spark.util.io.ChunkedByteBuffer.$anonfun$writeExternal$2(ChunkedByteBuffer.scala:103)\n",
      "\tat org.apache.spark.util.io.ChunkedByteBuffer.$anonfun$writeExternal$2$adapted(ChunkedByteBuffer.scala:103)\n",
      "\tat org.apache.spark.util.io.ChunkedByteBuffer$$Lambda$1650/1453017789.apply(Unknown Source)\n",
      "\tat scala.collection.IndexedSeqOptimized.foreach(IndexedSeqOptimized.scala:36)\n",
      "\tat scala.collection.IndexedSeqOptimized.foreach$(IndexedSeqOptimized.scala:33)\n",
      "\tat scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:198)\n",
      "\tat org.apache.spark.util.io.ChunkedByteBuffer.writeExternal(ChunkedByteBuffer.scala:103)\n",
      "\tat org.apache.spark.scheduler.DirectTaskResult.$anonfun$writeExternal$1(TaskResult.scala:60)\n",
      "\tat org.apache.spark.scheduler.DirectTaskResult$$Lambda$1648/1417649260.apply$mcV$sp(Unknown Source)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryOrIOException(SparkErrorUtils.scala:35)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryOrIOException$(SparkErrorUtils.scala:33)\n",
      "\tat org.apache.spark.util.Utils$.tryOrIOException(Utils.scala:94)\n",
      "\tat org.apache.spark.scheduler.DirectTaskResult.writeExternal(TaskResult.scala:59)\n",
      "\tat java.io.ObjectOutputStream.writeExternalData(ObjectOutputStream.java:1459)\n",
      "\tat java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1430)\n",
      "\tat java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1178)\n",
      "\tat java.io.ObjectOutputStream.writeObject(ObjectOutputStream.java:348)\n",
      "23/10/12 17:17:12 ERROR SparkUncaughtExceptionHandler: Uncaught exception in thread Thread[Executor task launch worker for task 2.0 in stage 1.0 (TID 3),5,main]\n",
      "java.lang.OutOfMemoryError: Java heap space\n",
      "\tat java.nio.HeapByteBuffer.<init>(HeapByteBuffer.java:57)\n",
      "\tat java.nio.ByteBuffer.allocate(ByteBuffer.java:335)\n",
      "\tat org.apache.spark.serializer.SerializerHelper$.$anonfun$serializeToChunkedBuffer$1(SerializerHelper.scala:40)\n",
      "\tat org.apache.spark.serializer.SerializerHelper$.$anonfun$serializeToChunkedBuffer$1$adapted(SerializerHelper.scala:40)\n",
      "\tat org.apache.spark.serializer.SerializerHelper$$$Lambda$1644/39752490.apply(Unknown Source)\n",
      "\tat org.apache.spark.util.io.ChunkedByteBufferOutputStream.allocateNewChunkIfNeeded(ChunkedByteBufferOutputStream.scala:87)\n",
      "\tat org.apache.spark.util.io.ChunkedByteBufferOutputStream.write(ChunkedByteBufferOutputStream.scala:75)\n",
      "\tat java.io.ObjectOutputStream$BlockDataOutputStream.write(ObjectOutputStream.java:1853)\n",
      "\tat java.io.ObjectOutputStream.write(ObjectOutputStream.java:709)\n",
      "\tat org.apache.spark.util.Utils$.$anonfun$writeByteBuffer$1(Utils.scala:209)\n",
      "\tat org.apache.spark.util.Utils$.$anonfun$writeByteBuffer$1$adapted(Utils.scala:209)\n",
      "\tat org.apache.spark.util.Utils$$$Lambda$1651/1509052106.apply(Unknown Source)\n",
      "\tat org.apache.spark.util.Utils$.writeByteBufferImpl(Utils.scala:187)\n",
      "\tat org.apache.spark.util.Utils$.writeByteBuffer(Utils.scala:209)\n",
      "\tat org.apache.spark.util.io.ChunkedByteBuffer.$anonfun$writeExternal$2(ChunkedByteBuffer.scala:103)\n",
      "\tat org.apache.spark.util.io.ChunkedByteBuffer.$anonfun$writeExternal$2$adapted(ChunkedByteBuffer.scala:103)\n",
      "\tat org.apache.spark.util.io.ChunkedByteBuffer$$Lambda$1650/1453017789.apply(Unknown Source)\n",
      "\tat scala.collection.IndexedSeqOptimized.foreach(IndexedSeqOptimized.scala:36)\n",
      "\tat scala.collection.IndexedSeqOptimized.foreach$(IndexedSeqOptimized.scala:33)\n",
      "\tat scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:198)\n",
      "\tat org.apache.spark.util.io.ChunkedByteBuffer.writeExternal(ChunkedByteBuffer.scala:103)\n",
      "\tat org.apache.spark.scheduler.DirectTaskResult.$anonfun$writeExternal$1(TaskResult.scala:60)\n",
      "\tat org.apache.spark.scheduler.DirectTaskResult$$Lambda$1648/1417649260.apply$mcV$sp(Unknown Source)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryOrIOException(SparkErrorUtils.scala:35)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryOrIOException$(SparkErrorUtils.scala:33)\n",
      "\tat org.apache.spark.util.Utils$.tryOrIOException(Utils.scala:94)\n",
      "\tat org.apache.spark.scheduler.DirectTaskResult.writeExternal(TaskResult.scala:59)\n",
      "\tat java.io.ObjectOutputStream.writeExternalData(ObjectOutputStream.java:1459)\n",
      "\tat java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1430)\n",
      "\tat java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1178)\n",
      "\tat java.io.ObjectOutputStream.writeObject(ObjectOutputStream.java:348)\n",
      "23/10/12 17:17:12 WARN TaskSetManager: Lost task 2.0 in stage 1.0 (TID 3) (192.168.2.137 executor driver): java.lang.OutOfMemoryError: Java heap space\n",
      "\tat java.nio.HeapByteBuffer.<init>(HeapByteBuffer.java:57)\n",
      "\tat java.nio.ByteBuffer.allocate(ByteBuffer.java:335)\n",
      "\tat org.apache.spark.serializer.SerializerHelper$.$anonfun$serializeToChunkedBuffer$1(SerializerHelper.scala:40)\n",
      "\tat org.apache.spark.serializer.SerializerHelper$.$anonfun$serializeToChunkedBuffer$1$adapted(SerializerHelper.scala:40)\n",
      "\tat org.apache.spark.serializer.SerializerHelper$$$Lambda$1644/39752490.apply(Unknown Source)\n",
      "\tat org.apache.spark.util.io.ChunkedByteBufferOutputStream.allocateNewChunkIfNeeded(ChunkedByteBufferOutputStream.scala:87)\n",
      "\tat org.apache.spark.util.io.ChunkedByteBufferOutputStream.write(ChunkedByteBufferOutputStream.scala:75)\n",
      "\tat java.io.ObjectOutputStream$BlockDataOutputStream.write(ObjectOutputStream.java:1853)\n",
      "\tat java.io.ObjectOutputStream.write(ObjectOutputStream.java:709)\n",
      "\tat org.apache.spark.util.Utils$.$anonfun$writeByteBuffer$1(Utils.scala:209)\n",
      "\tat org.apache.spark.util.Utils$.$anonfun$writeByteBuffer$1$adapted(Utils.scala:209)\n",
      "\tat org.apache.spark.util.Utils$$$Lambda$1651/1509052106.apply(Unknown Source)\n",
      "\tat org.apache.spark.util.Utils$.writeByteBufferImpl(Utils.scala:187)\n",
      "\tat org.apache.spark.util.Utils$.writeByteBuffer(Utils.scala:209)\n",
      "\tat org.apache.spark.util.io.ChunkedByteBuffer.$anonfun$writeExternal$2(ChunkedByteBuffer.scala:103)\n",
      "\tat org.apache.spark.util.io.ChunkedByteBuffer.$anonfun$writeExternal$2$adapted(ChunkedByteBuffer.scala:103)\n",
      "\tat org.apache.spark.util.io.ChunkedByteBuffer$$Lambda$1650/1453017789.apply(Unknown Source)\n",
      "\tat scala.collection.IndexedSeqOptimized.foreach(IndexedSeqOptimized.scala:36)\n",
      "\tat scala.collection.IndexedSeqOptimized.foreach$(IndexedSeqOptimized.scala:33)\n",
      "\tat scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:198)\n",
      "\tat org.apache.spark.util.io.ChunkedByteBuffer.writeExternal(ChunkedByteBuffer.scala:103)\n",
      "\tat org.apache.spark.scheduler.DirectTaskResult.$anonfun$writeExternal$1(TaskResult.scala:60)\n",
      "\tat org.apache.spark.scheduler.DirectTaskResult$$Lambda$1648/1417649260.apply$mcV$sp(Unknown Source)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryOrIOException(SparkErrorUtils.scala:35)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryOrIOException$(SparkErrorUtils.scala:33)\n",
      "\tat org.apache.spark.util.Utils$.tryOrIOException(Utils.scala:94)\n",
      "\tat org.apache.spark.scheduler.DirectTaskResult.writeExternal(TaskResult.scala:59)\n",
      "\tat java.io.ObjectOutputStream.writeExternalData(ObjectOutputStream.java:1459)\n",
      "\tat java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1430)\n",
      "\tat java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1178)\n",
      "\tat java.io.ObjectOutputStream.writeObject(ObjectOutputStream.java:348)\n",
      "\n",
      "23/10/12 17:17:12 ERROR TaskSetManager: Task 2 in stage 1.0 failed 1 times; aborting job\n",
      "23/10/12 17:17:14 WARN TaskSetManager: Lost task 4.0 in stage 1.0 (TID 5) (192.168.2.137 executor driver): TaskKilled (Stage cancelled: Job aborted due to stage failure: Task 2 in stage 1.0 failed 1 times, most recent failure: Lost task 2.0 in stage 1.0 (TID 3) (192.168.2.137 executor driver): java.lang.OutOfMemoryError: Java heap space\n",
      "\tat java.nio.HeapByteBuffer.<init>(HeapByteBuffer.java:57)\n",
      "\tat java.nio.ByteBuffer.allocate(ByteBuffer.java:335)\n",
      "\tat org.apache.spark.serializer.SerializerHelper$.$anonfun$serializeToChunkedBuffer$1(SerializerHelper.scala:40)\n",
      "\tat org.apache.spark.serializer.SerializerHelper$.$anonfun$serializeToChunkedBuffer$1$adapted(SerializerHelper.scala:40)\n",
      "\tat org.apache.spark.serializer.SerializerHelper$$$Lambda$1644/39752490.apply(Unknown Source)\n",
      "\tat org.apache.spark.util.io.ChunkedByteBufferOutputStream.allocateNewChunkIfNeeded(ChunkedByteBufferOutputStream.scala:87)\n",
      "\tat org.apache.spark.util.io.ChunkedByteBufferOutputStream.write(ChunkedByteBufferOutputStream.scala:75)\n",
      "\tat java.io.ObjectOutputStream$BlockDataOutputStream.write(ObjectOutputStream.java:1853)\n",
      "\tat java.io.ObjectOutputStream.write(ObjectOutputStream.java:709)\n",
      "\tat org.apache.spark.util.Utils$.$anonfun$writeByteBuffer$1(Utils.scala:209)\n",
      "\tat org.apache.spark.util.Utils$.$anonfun$writeByteBuffer$1$adapted(Utils.scala:209)\n",
      "\tat org.apache.spark.util.Utils$$$Lambda$1651/1509052106.apply(Unknown Source)\n",
      "\tat org.apache.spark.util.Utils$.writeByteBufferImpl(Utils.scala:187)\n",
      "\tat org.apache.spark.util.Utils$.writeByteBuffer(Utils.scala:209)\n",
      "\tat org.apache.spark.util.io.ChunkedByteBuffer.$anonfun$writeExternal$2(ChunkedByteBuffer.scala:103)\n",
      "\tat org.apache.spark.util.io.ChunkedByteBuffer.$anonfun$writeExternal$2$adapted(ChunkedByteBuffer.scala:103)\n",
      "\tat org.apache.spark.util.io.ChunkedByteBuffer$$Lambda$1650/1453017789.apply(Unknown Source)\n",
      "\tat scala.collection.IndexedSeqOptimized.foreach(IndexedSeqOptimized.scala:36)\n",
      "\tat scala.collection.IndexedSeqOptimized.foreach$(IndexedSeqOptimized.scala:33)\n",
      "\tat scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:198)\n",
      "\tat org.apache.spark.util.io.ChunkedByteBuffer.writeExternal(ChunkedByteBuffer.scala:103)\n",
      "\tat org.apache.spark.scheduler.DirectTaskResult.$anonfun$writeExternal$1(TaskResult.scala:60)\n",
      "\tat org.apache.spark.scheduler.DirectTaskResult$$Lambda$1648/1417649260.apply$mcV$sp(Unknown Source)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryOrIOException(SparkErrorUtils.scala:35)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryOrIOException$(SparkErrorUtils.scala:33)\n",
      "\tat org.apache.spark.util.Utils$.tryOrIOException(Utils.scala:94)\n",
      "\tat org.apache.spark.scheduler.DirectTaskResult.writeExternal(TaskResult.scala:59)\n",
      "\tat java.io.ObjectOutputStream.writeExternalData(ObjectOutputStream.java:1459)\n",
      "\tat java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1430)\n",
      "\tat java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1178)\n",
      "\tat java.io.ObjectOutputStream.writeObject(ObjectOutputStream.java:348)\n",
      "\n",
      "Driver stacktrace:)\n",
      "23/10/12 17:17:14 WARN TaskSetManager: Lost task 6.0 in stage 1.0 (TID 7) (192.168.2.137 executor driver): TaskKilled (Stage cancelled: Job aborted due to stage failure: Task 2 in stage 1.0 failed 1 times, most recent failure: Lost task 2.0 in stage 1.0 (TID 3) (192.168.2.137 executor driver): java.lang.OutOfMemoryError: Java heap space\n",
      "\tat java.nio.HeapByteBuffer.<init>(HeapByteBuffer.java:57)\n",
      "\tat java.nio.ByteBuffer.allocate(ByteBuffer.java:335)\n",
      "\tat org.apache.spark.serializer.SerializerHelper$.$anonfun$serializeToChunkedBuffer$1(SerializerHelper.scala:40)\n",
      "\tat org.apache.spark.serializer.SerializerHelper$.$anonfun$serializeToChunkedBuffer$1$adapted(SerializerHelper.scala:40)\n",
      "\tat org.apache.spark.serializer.SerializerHelper$$$Lambda$1644/39752490.apply(Unknown Source)\n",
      "\tat org.apache.spark.util.io.ChunkedByteBufferOutputStream.allocateNewChunkIfNeeded(ChunkedByteBufferOutputStream.scala:87)\n",
      "\tat org.apache.spark.util.io.ChunkedByteBufferOutputStream.write(ChunkedByteBufferOutputStream.scala:75)\n",
      "\tat java.io.ObjectOutputStream$BlockDataOutputStream.write(ObjectOutputStream.java:1853)\n",
      "\tat java.io.ObjectOutputStream.write(ObjectOutputStream.java:709)\n",
      "\tat org.apache.spark.util.Utils$.$anonfun$writeByteBuffer$1(Utils.scala:209)\n",
      "\tat org.apache.spark.util.Utils$.$anonfun$writeByteBuffer$1$adapted(Utils.scala:209)\n",
      "\tat org.apache.spark.util.Utils$$$Lambda$1651/1509052106.apply(Unknown Source)\n",
      "\tat org.apache.spark.util.Utils$.writeByteBufferImpl(Utils.scala:187)\n",
      "\tat org.apache.spark.util.Utils$.writeByteBuffer(Utils.scala:209)\n",
      "\tat org.apache.spark.util.io.ChunkedByteBuffer.$anonfun$writeExternal$2(ChunkedByteBuffer.scala:103)\n",
      "\tat org.apache.spark.util.io.ChunkedByteBuffer.$anonfun$writeExternal$2$adapted(ChunkedByteBuffer.scala:103)\n",
      "\tat org.apache.spark.util.io.ChunkedByteBuffer$$Lambda$1650/1453017789.apply(Unknown Source)\n",
      "\tat scala.collection.IndexedSeqOptimized.foreach(IndexedSeqOptimized.scala:36)\n",
      "\tat scala.collection.IndexedSeqOptimized.foreach$(IndexedSeqOptimized.scala:33)\n",
      "\tat scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:198)\n",
      "\tat org.apache.spark.util.io.ChunkedByteBuffer.writeExternal(ChunkedByteBuffer.scala:103)\n",
      "\tat org.apache.spark.scheduler.DirectTaskResult.$anonfun$writeExternal$1(TaskResult.scala:60)\n",
      "\tat org.apache.spark.scheduler.DirectTaskResult$$Lambda$1648/1417649260.apply$mcV$sp(Unknown Source)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryOrIOException(SparkErrorUtils.scala:35)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryOrIOException$(SparkErrorUtils.scala:33)\n",
      "\tat org.apache.spark.util.Utils$.tryOrIOException(Utils.scala:94)\n",
      "\tat org.apache.spark.scheduler.DirectTaskResult.writeExternal(TaskResult.scala:59)\n",
      "\tat java.io.ObjectOutputStream.writeExternalData(ObjectOutputStream.java:1459)\n",
      "\tat java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1430)\n",
      "\tat java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1178)\n",
      "\tat java.io.ObjectOutputStream.writeObject(ObjectOutputStream.java:348)\n",
      "\n",
      "Driver stacktrace:)\n",
      "23/10/12 17:17:14 WARN TaskSetManager: Lost task 3.0 in stage 1.0 (TID 4) (192.168.2.137 executor driver): TaskKilled (Stage cancelled: Job aborted due to stage failure: Task 2 in stage 1.0 failed 1 times, most recent failure: Lost task 2.0 in stage 1.0 (TID 3) (192.168.2.137 executor driver): java.lang.OutOfMemoryError: Java heap space\n",
      "\tat java.nio.HeapByteBuffer.<init>(HeapByteBuffer.java:57)\n",
      "\tat java.nio.ByteBuffer.allocate(ByteBuffer.java:335)\n",
      "\tat org.apache.spark.serializer.SerializerHelper$.$anonfun$serializeToChunkedBuffer$1(SerializerHelper.scala:40)\n",
      "\tat org.apache.spark.serializer.SerializerHelper$.$anonfun$serializeToChunkedBuffer$1$adapted(SerializerHelper.scala:40)\n",
      "\tat org.apache.spark.serializer.SerializerHelper$$$Lambda$1644/39752490.apply(Unknown Source)\n",
      "\tat org.apache.spark.util.io.ChunkedByteBufferOutputStream.allocateNewChunkIfNeeded(ChunkedByteBufferOutputStream.scala:87)\n",
      "\tat org.apache.spark.util.io.ChunkedByteBufferOutputStream.write(ChunkedByteBufferOutputStream.scala:75)\n",
      "\tat java.io.ObjectOutputStream$BlockDataOutputStream.write(ObjectOutputStream.java:1853)\n",
      "\tat java.io.ObjectOutputStream.write(ObjectOutputStream.java:709)\n",
      "\tat org.apache.spark.util.Utils$.$anonfun$writeByteBuffer$1(Utils.scala:209)\n",
      "\tat org.apache.spark.util.Utils$.$anonfun$writeByteBuffer$1$adapted(Utils.scala:209)\n",
      "\tat org.apache.spark.util.Utils$$$Lambda$1651/1509052106.apply(Unknown Source)\n",
      "\tat org.apache.spark.util.Utils$.writeByteBufferImpl(Utils.scala:187)\n",
      "\tat org.apache.spark.util.Utils$.writeByteBuffer(Utils.scala:209)\n",
      "\tat org.apache.spark.util.io.ChunkedByteBuffer.$anonfun$writeExternal$2(ChunkedByteBuffer.scala:103)\n",
      "\tat org.apache.spark.util.io.ChunkedByteBuffer.$anonfun$writeExternal$2$adapted(ChunkedByteBuffer.scala:103)\n",
      "\tat org.apache.spark.util.io.ChunkedByteBuffer$$Lambda$1650/1453017789.apply(Unknown Source)\n",
      "\tat scala.collection.IndexedSeqOptimized.foreach(IndexedSeqOptimized.scala:36)\n",
      "\tat scala.collection.IndexedSeqOptimized.foreach$(IndexedSeqOptimized.scala:33)\n",
      "\tat scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:198)\n",
      "\tat org.apache.spark.util.io.ChunkedByteBuffer.writeExternal(ChunkedByteBuffer.scala:103)\n",
      "\tat org.apache.spark.scheduler.DirectTaskResult.$anonfun$writeExternal$1(TaskResult.scala:60)\n",
      "\tat org.apache.spark.scheduler.DirectTaskResult$$Lambda$1648/1417649260.apply$mcV$sp(Unknown Source)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryOrIOException(SparkErrorUtils.scala:35)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryOrIOException$(SparkErrorUtils.scala:33)\n",
      "\tat org.apache.spark.util.Utils$.tryOrIOException(Utils.scala:94)\n",
      "\tat org.apache.spark.scheduler.DirectTaskResult.writeExternal(TaskResult.scala:59)\n",
      "\tat java.io.ObjectOutputStream.writeExternalData(ObjectOutputStream.java:1459)\n",
      "\tat java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1430)\n",
      "\tat java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1178)\n",
      "\tat java.io.ObjectOutputStream.writeObject(ObjectOutputStream.java:348)\n",
      "\n",
      "Driver stacktrace:)\n",
      "23/10/12 17:17:14 ERROR Utils: Uncaught exception in thread task-result-getter-3\n",
      "java.lang.InterruptedException\n",
      "\tat java.util.concurrent.locks.AbstractQueuedSynchronizer.doAcquireSharedInterruptibly(AbstractQueuedSynchronizer.java:998)\n",
      "\tat java.util.concurrent.locks.AbstractQueuedSynchronizer.acquireSharedInterruptibly(AbstractQueuedSynchronizer.java:1304)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryAwait(Promise.scala:242)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.ready(Promise.scala:258)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.result(Promise.scala:263)\n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:48)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.network.BlockTransferService.fetchBlockSync(BlockTransferService.scala:103)\n",
      "\tat org.apache.spark.storage.BlockManager.fetchRemoteManagedBuffer(BlockManager.scala:1172)\n",
      "\tat org.apache.spark.storage.BlockManager.$anonfun$getRemoteBlock$8(BlockManager.scala:1116)\n",
      "\tat scala.Option.orElse(Option.scala:447)\n",
      "\tat org.apache.spark.storage.BlockManager.getRemoteBlock(BlockManager.scala:1116)\n",
      "\tat org.apache.spark.storage.BlockManager.getRemoteBytes(BlockManager.scala:1256)\n",
      "\tat org.apache.spark.scheduler.TaskResultGetter$$anon$3.$anonfun$run$1(TaskResultGetter.scala:88)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.scheduler.TaskResultGetter$$anon$3.run(TaskResultGetter.scala:63)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Exception in thread \"task-result-getter-3\" java.lang.Error: java.lang.InterruptedException\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1155)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: java.lang.InterruptedException\n",
      "\tat java.util.concurrent.locks.AbstractQueuedSynchronizer.doAcquireSharedInterruptibly(AbstractQueuedSynchronizer.java:998)\n",
      "\tat java.util.concurrent.locks.AbstractQueuedSynchronizer.acquireSharedInterruptibly(AbstractQueuedSynchronizer.java:1304)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryAwait(Promise.scala:242)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.ready(Promise.scala:258)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.result(Promise.scala:263)\n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:48)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.network.BlockTransferService.fetchBlockSync(BlockTransferService.scala:103)\n",
      "\tat org.apache.spark.storage.BlockManager.fetchRemoteManagedBuffer(BlockManager.scala:1172)\n",
      "\tat org.apache.spark.storage.BlockManager.$anonfun$getRemoteBlock$8(BlockManager.scala:1116)\n",
      "\tat scala.Option.orElse(Option.scala:447)\n",
      "\tat org.apache.spark.storage.BlockManager.getRemoteBlock(BlockManager.scala:1116)\n",
      "\tat org.apache.spark.storage.BlockManager.getRemoteBytes(BlockManager.scala:1256)\n",
      "\tat org.apache.spark.scheduler.TaskResultGetter$$anon$3.$anonfun$run$1(TaskResultGetter.scala:88)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.scheduler.TaskResultGetter$$anon$3.run(TaskResultGetter.scala:63)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\t... 2 more\n",
      "23/10/12 17:17:14 ERROR ChunkFetchRequestHandler: Error sending result ChunkFetchSuccess[streamChunkId=StreamChunkId[streamId=1133366750001,chunkIndex=0],buffer=org.apache.spark.storage.BlockManagerManagedBuffer@67dfa20c] to /192.168.2.137:50323; closing connection\n",
      "io.netty.channel.StacklessClosedChannelException\n",
      "\tat io.netty.channel.AbstractChannel.close(ChannelPromise)(Unknown Source)\n",
      "23/10/12 17:17:14 ERROR TransportResponseHandler: Still have 1 requests outstanding when connection from /192.168.2.137:49828 is closed\n"
     ]
    },
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling o30.collectToPython.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 2 in stage 1.0 failed 1 times, most recent failure: Lost task 2.0 in stage 1.0 (TID 3) (192.168.2.137 executor driver): java.lang.OutOfMemoryError: Java heap space\n\tat java.nio.HeapByteBuffer.<init>(HeapByteBuffer.java:57)\n\tat java.nio.ByteBuffer.allocate(ByteBuffer.java:335)\n\tat org.apache.spark.serializer.SerializerHelper$.$anonfun$serializeToChunkedBuffer$1(SerializerHelper.scala:40)\n\tat org.apache.spark.serializer.SerializerHelper$.$anonfun$serializeToChunkedBuffer$1$adapted(SerializerHelper.scala:40)\n\tat org.apache.spark.serializer.SerializerHelper$$$Lambda$1644/39752490.apply(Unknown Source)\n\tat org.apache.spark.util.io.ChunkedByteBufferOutputStream.allocateNewChunkIfNeeded(ChunkedByteBufferOutputStream.scala:87)\n\tat org.apache.spark.util.io.ChunkedByteBufferOutputStream.write(ChunkedByteBufferOutputStream.scala:75)\n\tat java.io.ObjectOutputStream$BlockDataOutputStream.write(ObjectOutputStream.java:1853)\n\tat java.io.ObjectOutputStream.write(ObjectOutputStream.java:709)\n\tat org.apache.spark.util.Utils$.$anonfun$writeByteBuffer$1(Utils.scala:209)\n\tat org.apache.spark.util.Utils$.$anonfun$writeByteBuffer$1$adapted(Utils.scala:209)\n\tat org.apache.spark.util.Utils$$$Lambda$1651/1509052106.apply(Unknown Source)\n\tat org.apache.spark.util.Utils$.writeByteBufferImpl(Utils.scala:187)\n\tat org.apache.spark.util.Utils$.writeByteBuffer(Utils.scala:209)\n\tat org.apache.spark.util.io.ChunkedByteBuffer.$anonfun$writeExternal$2(ChunkedByteBuffer.scala:103)\n\tat org.apache.spark.util.io.ChunkedByteBuffer.$anonfun$writeExternal$2$adapted(ChunkedByteBuffer.scala:103)\n\tat org.apache.spark.util.io.ChunkedByteBuffer$$Lambda$1650/1453017789.apply(Unknown Source)\n\tat scala.collection.IndexedSeqOptimized.foreach(IndexedSeqOptimized.scala:36)\n\tat scala.collection.IndexedSeqOptimized.foreach$(IndexedSeqOptimized.scala:33)\n\tat scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:198)\n\tat org.apache.spark.util.io.ChunkedByteBuffer.writeExternal(ChunkedByteBuffer.scala:103)\n\tat org.apache.spark.scheduler.DirectTaskResult.$anonfun$writeExternal$1(TaskResult.scala:60)\n\tat org.apache.spark.scheduler.DirectTaskResult$$Lambda$1648/1417649260.apply$mcV$sp(Unknown Source)\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n\tat org.apache.spark.util.SparkErrorUtils.tryOrIOException(SparkErrorUtils.scala:35)\n\tat org.apache.spark.util.SparkErrorUtils.tryOrIOException$(SparkErrorUtils.scala:33)\n\tat org.apache.spark.util.Utils$.tryOrIOException(Utils.scala:94)\n\tat org.apache.spark.scheduler.DirectTaskResult.writeExternal(TaskResult.scala:59)\n\tat java.io.ObjectOutputStream.writeExternalData(ObjectOutputStream.java:1459)\n\tat java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1430)\n\tat java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1178)\n\tat java.io.ObjectOutputStream.writeObject(ObjectOutputStream.java:348)\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2844)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2780)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2779)\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2779)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1242)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1242)\n\tat scala.Option.foreach(Option.scala:407)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1242)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:3048)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2982)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2971)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:984)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2398)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2419)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2438)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2463)\n\tat org.apache.spark.rdd.RDD.$anonfun$collect$1(RDD.scala:1046)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:407)\n\tat org.apache.spark.rdd.RDD.collect(RDD.scala:1045)\n\tat org.apache.spark.sql.execution.SparkPlan.executeCollect(SparkPlan.scala:448)\n\tat org.apache.spark.sql.Dataset.$anonfun$collectToPython$1(Dataset.scala:4160)\n\tat org.apache.spark.sql.Dataset.$anonfun$withAction$2(Dataset.scala:4334)\n\tat org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)\n\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:4332)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:4332)\n\tat org.apache.spark.sql.Dataset.collectToPython(Dataset.scala:4157)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n\tat java.lang.Thread.run(Thread.java:750)\nCaused by: java.lang.OutOfMemoryError: Java heap space\n\tat java.nio.HeapByteBuffer.<init>(HeapByteBuffer.java:57)\n\tat java.nio.ByteBuffer.allocate(ByteBuffer.java:335)\n\tat org.apache.spark.serializer.SerializerHelper$.$anonfun$serializeToChunkedBuffer$1(SerializerHelper.scala:40)\n\tat org.apache.spark.serializer.SerializerHelper$.$anonfun$serializeToChunkedBuffer$1$adapted(SerializerHelper.scala:40)\n\tat org.apache.spark.serializer.SerializerHelper$$$Lambda$1644/39752490.apply(Unknown Source)\n\tat org.apache.spark.util.io.ChunkedByteBufferOutputStream.allocateNewChunkIfNeeded(ChunkedByteBufferOutputStream.scala:87)\n\tat org.apache.spark.util.io.ChunkedByteBufferOutputStream.write(ChunkedByteBufferOutputStream.scala:75)\n\tat java.io.ObjectOutputStream$BlockDataOutputStream.write(ObjectOutputStream.java:1853)\n\tat java.io.ObjectOutputStream.write(ObjectOutputStream.java:709)\n\tat org.apache.spark.util.Utils$.$anonfun$writeByteBuffer$1(Utils.scala:209)\n\tat org.apache.spark.util.Utils$.$anonfun$writeByteBuffer$1$adapted(Utils.scala:209)\n\tat org.apache.spark.util.Utils$$$Lambda$1651/1509052106.apply(Unknown Source)\n\tat org.apache.spark.util.Utils$.writeByteBufferImpl(Utils.scala:187)\n\tat org.apache.spark.util.Utils$.writeByteBuffer(Utils.scala:209)\n\tat org.apache.spark.util.io.ChunkedByteBuffer.$anonfun$writeExternal$2(ChunkedByteBuffer.scala:103)\n\tat org.apache.spark.util.io.ChunkedByteBuffer.$anonfun$writeExternal$2$adapted(ChunkedByteBuffer.scala:103)\n\tat org.apache.spark.util.io.ChunkedByteBuffer$$Lambda$1650/1453017789.apply(Unknown Source)\n\tat scala.collection.IndexedSeqOptimized.foreach(IndexedSeqOptimized.scala:36)\n\tat scala.collection.IndexedSeqOptimized.foreach$(IndexedSeqOptimized.scala:33)\n\tat scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:198)\n\tat org.apache.spark.util.io.ChunkedByteBuffer.writeExternal(ChunkedByteBuffer.scala:103)\n\tat org.apache.spark.scheduler.DirectTaskResult.$anonfun$writeExternal$1(TaskResult.scala:60)\n\tat org.apache.spark.scheduler.DirectTaskResult$$Lambda$1648/1417649260.apply$mcV$sp(Unknown Source)\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n\tat org.apache.spark.util.SparkErrorUtils.tryOrIOException(SparkErrorUtils.scala:35)\n\tat org.apache.spark.util.SparkErrorUtils.tryOrIOException$(SparkErrorUtils.scala:33)\n\tat org.apache.spark.util.Utils$.tryOrIOException(Utils.scala:94)\n\tat org.apache.spark.scheduler.DirectTaskResult.writeExternal(TaskResult.scala:59)\n\tat java.io.ObjectOutputStream.writeExternalData(ObjectOutputStream.java:1459)\n\tat java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1430)\n\tat java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1178)\n\tat java.io.ObjectOutputStream.writeObject(ObjectOutputStream.java:348)\n",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mPy4JJavaError\u001B[0m                             Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[10], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m modded_df \u001B[38;5;241m=\u001B[39m \u001B[43mmodded\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtoPandas\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/Hackathon3/venv/lib/python3.10/site-packages/pyspark/sql/pandas/conversion.py:202\u001B[0m, in \u001B[0;36mPandasConversionMixin.toPandas\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    199\u001B[0m             \u001B[38;5;28;01mraise\u001B[39;00m\n\u001B[1;32m    201\u001B[0m \u001B[38;5;66;03m# Below is toPandas without Arrow optimization.\u001B[39;00m\n\u001B[0;32m--> 202\u001B[0m rows \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcollect\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    203\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(rows) \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m    204\u001B[0m     pdf \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mDataFrame\u001B[38;5;241m.\u001B[39mfrom_records(\n\u001B[1;32m    205\u001B[0m         rows, index\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mrange\u001B[39m(\u001B[38;5;28mlen\u001B[39m(rows)), columns\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcolumns  \u001B[38;5;66;03m# type: ignore[arg-type]\u001B[39;00m\n\u001B[1;32m    206\u001B[0m     )\n",
      "File \u001B[0;32m~/PycharmProjects/Hackathon3/venv/lib/python3.10/site-packages/pyspark/sql/dataframe.py:1257\u001B[0m, in \u001B[0;36mDataFrame.collect\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   1237\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Returns all the records as a list of :class:`Row`.\u001B[39;00m\n\u001B[1;32m   1238\u001B[0m \n\u001B[1;32m   1239\u001B[0m \u001B[38;5;124;03m.. versionadded:: 1.3.0\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1254\u001B[0m \u001B[38;5;124;03m[Row(age=14, name='Tom'), Row(age=23, name='Alice'), Row(age=16, name='Bob')]\u001B[39;00m\n\u001B[1;32m   1255\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m   1256\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m SCCallSiteSync(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sc):\n\u001B[0;32m-> 1257\u001B[0m     sock_info \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_jdf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcollectToPython\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1258\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mlist\u001B[39m(_load_from_socket(sock_info, BatchedSerializer(CPickleSerializer())))\n",
      "File \u001B[0;32m~/PycharmProjects/Hackathon3/venv/lib/python3.10/site-packages/py4j/java_gateway.py:1322\u001B[0m, in \u001B[0;36mJavaMember.__call__\u001B[0;34m(self, *args)\u001B[0m\n\u001B[1;32m   1316\u001B[0m command \u001B[38;5;241m=\u001B[39m proto\u001B[38;5;241m.\u001B[39mCALL_COMMAND_NAME \u001B[38;5;241m+\u001B[39m\\\n\u001B[1;32m   1317\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcommand_header \u001B[38;5;241m+\u001B[39m\\\n\u001B[1;32m   1318\u001B[0m     args_command \u001B[38;5;241m+\u001B[39m\\\n\u001B[1;32m   1319\u001B[0m     proto\u001B[38;5;241m.\u001B[39mEND_COMMAND_PART\n\u001B[1;32m   1321\u001B[0m answer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgateway_client\u001B[38;5;241m.\u001B[39msend_command(command)\n\u001B[0;32m-> 1322\u001B[0m return_value \u001B[38;5;241m=\u001B[39m \u001B[43mget_return_value\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1323\u001B[0m \u001B[43m    \u001B[49m\u001B[43manswer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgateway_client\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtarget_id\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1325\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m temp_arg \u001B[38;5;129;01min\u001B[39;00m temp_args:\n\u001B[1;32m   1326\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(temp_arg, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m_detach\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n",
      "File \u001B[0;32m~/PycharmProjects/Hackathon3/venv/lib/python3.10/site-packages/pyspark/errors/exceptions/captured.py:179\u001B[0m, in \u001B[0;36mcapture_sql_exception.<locals>.deco\u001B[0;34m(*a, **kw)\u001B[0m\n\u001B[1;32m    177\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mdeco\u001B[39m(\u001B[38;5;241m*\u001B[39ma: Any, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkw: Any) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Any:\n\u001B[1;32m    178\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 179\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mf\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43ma\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkw\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    180\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m Py4JJavaError \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    181\u001B[0m         converted \u001B[38;5;241m=\u001B[39m convert_exception(e\u001B[38;5;241m.\u001B[39mjava_exception)\n",
      "File \u001B[0;32m~/PycharmProjects/Hackathon3/venv/lib/python3.10/site-packages/py4j/protocol.py:326\u001B[0m, in \u001B[0;36mget_return_value\u001B[0;34m(answer, gateway_client, target_id, name)\u001B[0m\n\u001B[1;32m    324\u001B[0m value \u001B[38;5;241m=\u001B[39m OUTPUT_CONVERTER[\u001B[38;5;28mtype\u001B[39m](answer[\u001B[38;5;241m2\u001B[39m:], gateway_client)\n\u001B[1;32m    325\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m answer[\u001B[38;5;241m1\u001B[39m] \u001B[38;5;241m==\u001B[39m REFERENCE_TYPE:\n\u001B[0;32m--> 326\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m Py4JJavaError(\n\u001B[1;32m    327\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mAn error occurred while calling \u001B[39m\u001B[38;5;132;01m{0}\u001B[39;00m\u001B[38;5;132;01m{1}\u001B[39;00m\u001B[38;5;132;01m{2}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39m\n\u001B[1;32m    328\u001B[0m         \u001B[38;5;28mformat\u001B[39m(target_id, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m, name), value)\n\u001B[1;32m    329\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    330\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m Py4JError(\n\u001B[1;32m    331\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mAn error occurred while calling \u001B[39m\u001B[38;5;132;01m{0}\u001B[39;00m\u001B[38;5;132;01m{1}\u001B[39;00m\u001B[38;5;132;01m{2}\u001B[39;00m\u001B[38;5;124m. Trace:\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;132;01m{3}\u001B[39;00m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39m\n\u001B[1;32m    332\u001B[0m         \u001B[38;5;28mformat\u001B[39m(target_id, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m, name, value))\n",
      "\u001B[0;31mPy4JJavaError\u001B[0m: An error occurred while calling o30.collectToPython.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 2 in stage 1.0 failed 1 times, most recent failure: Lost task 2.0 in stage 1.0 (TID 3) (192.168.2.137 executor driver): java.lang.OutOfMemoryError: Java heap space\n\tat java.nio.HeapByteBuffer.<init>(HeapByteBuffer.java:57)\n\tat java.nio.ByteBuffer.allocate(ByteBuffer.java:335)\n\tat org.apache.spark.serializer.SerializerHelper$.$anonfun$serializeToChunkedBuffer$1(SerializerHelper.scala:40)\n\tat org.apache.spark.serializer.SerializerHelper$.$anonfun$serializeToChunkedBuffer$1$adapted(SerializerHelper.scala:40)\n\tat org.apache.spark.serializer.SerializerHelper$$$Lambda$1644/39752490.apply(Unknown Source)\n\tat org.apache.spark.util.io.ChunkedByteBufferOutputStream.allocateNewChunkIfNeeded(ChunkedByteBufferOutputStream.scala:87)\n\tat org.apache.spark.util.io.ChunkedByteBufferOutputStream.write(ChunkedByteBufferOutputStream.scala:75)\n\tat java.io.ObjectOutputStream$BlockDataOutputStream.write(ObjectOutputStream.java:1853)\n\tat java.io.ObjectOutputStream.write(ObjectOutputStream.java:709)\n\tat org.apache.spark.util.Utils$.$anonfun$writeByteBuffer$1(Utils.scala:209)\n\tat org.apache.spark.util.Utils$.$anonfun$writeByteBuffer$1$adapted(Utils.scala:209)\n\tat org.apache.spark.util.Utils$$$Lambda$1651/1509052106.apply(Unknown Source)\n\tat org.apache.spark.util.Utils$.writeByteBufferImpl(Utils.scala:187)\n\tat org.apache.spark.util.Utils$.writeByteBuffer(Utils.scala:209)\n\tat org.apache.spark.util.io.ChunkedByteBuffer.$anonfun$writeExternal$2(ChunkedByteBuffer.scala:103)\n\tat org.apache.spark.util.io.ChunkedByteBuffer.$anonfun$writeExternal$2$adapted(ChunkedByteBuffer.scala:103)\n\tat org.apache.spark.util.io.ChunkedByteBuffer$$Lambda$1650/1453017789.apply(Unknown Source)\n\tat scala.collection.IndexedSeqOptimized.foreach(IndexedSeqOptimized.scala:36)\n\tat scala.collection.IndexedSeqOptimized.foreach$(IndexedSeqOptimized.scala:33)\n\tat scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:198)\n\tat org.apache.spark.util.io.ChunkedByteBuffer.writeExternal(ChunkedByteBuffer.scala:103)\n\tat org.apache.spark.scheduler.DirectTaskResult.$anonfun$writeExternal$1(TaskResult.scala:60)\n\tat org.apache.spark.scheduler.DirectTaskResult$$Lambda$1648/1417649260.apply$mcV$sp(Unknown Source)\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n\tat org.apache.spark.util.SparkErrorUtils.tryOrIOException(SparkErrorUtils.scala:35)\n\tat org.apache.spark.util.SparkErrorUtils.tryOrIOException$(SparkErrorUtils.scala:33)\n\tat org.apache.spark.util.Utils$.tryOrIOException(Utils.scala:94)\n\tat org.apache.spark.scheduler.DirectTaskResult.writeExternal(TaskResult.scala:59)\n\tat java.io.ObjectOutputStream.writeExternalData(ObjectOutputStream.java:1459)\n\tat java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1430)\n\tat java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1178)\n\tat java.io.ObjectOutputStream.writeObject(ObjectOutputStream.java:348)\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2844)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2780)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2779)\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2779)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1242)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1242)\n\tat scala.Option.foreach(Option.scala:407)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1242)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:3048)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2982)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2971)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:984)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2398)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2419)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2438)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2463)\n\tat org.apache.spark.rdd.RDD.$anonfun$collect$1(RDD.scala:1046)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:407)\n\tat org.apache.spark.rdd.RDD.collect(RDD.scala:1045)\n\tat org.apache.spark.sql.execution.SparkPlan.executeCollect(SparkPlan.scala:448)\n\tat org.apache.spark.sql.Dataset.$anonfun$collectToPython$1(Dataset.scala:4160)\n\tat org.apache.spark.sql.Dataset.$anonfun$withAction$2(Dataset.scala:4334)\n\tat org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)\n\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:4332)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:4332)\n\tat org.apache.spark.sql.Dataset.collectToPython(Dataset.scala:4157)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n\tat java.lang.Thread.run(Thread.java:750)\nCaused by: java.lang.OutOfMemoryError: Java heap space\n\tat java.nio.HeapByteBuffer.<init>(HeapByteBuffer.java:57)\n\tat java.nio.ByteBuffer.allocate(ByteBuffer.java:335)\n\tat org.apache.spark.serializer.SerializerHelper$.$anonfun$serializeToChunkedBuffer$1(SerializerHelper.scala:40)\n\tat org.apache.spark.serializer.SerializerHelper$.$anonfun$serializeToChunkedBuffer$1$adapted(SerializerHelper.scala:40)\n\tat org.apache.spark.serializer.SerializerHelper$$$Lambda$1644/39752490.apply(Unknown Source)\n\tat org.apache.spark.util.io.ChunkedByteBufferOutputStream.allocateNewChunkIfNeeded(ChunkedByteBufferOutputStream.scala:87)\n\tat org.apache.spark.util.io.ChunkedByteBufferOutputStream.write(ChunkedByteBufferOutputStream.scala:75)\n\tat java.io.ObjectOutputStream$BlockDataOutputStream.write(ObjectOutputStream.java:1853)\n\tat java.io.ObjectOutputStream.write(ObjectOutputStream.java:709)\n\tat org.apache.spark.util.Utils$.$anonfun$writeByteBuffer$1(Utils.scala:209)\n\tat org.apache.spark.util.Utils$.$anonfun$writeByteBuffer$1$adapted(Utils.scala:209)\n\tat org.apache.spark.util.Utils$$$Lambda$1651/1509052106.apply(Unknown Source)\n\tat org.apache.spark.util.Utils$.writeByteBufferImpl(Utils.scala:187)\n\tat org.apache.spark.util.Utils$.writeByteBuffer(Utils.scala:209)\n\tat org.apache.spark.util.io.ChunkedByteBuffer.$anonfun$writeExternal$2(ChunkedByteBuffer.scala:103)\n\tat org.apache.spark.util.io.ChunkedByteBuffer.$anonfun$writeExternal$2$adapted(ChunkedByteBuffer.scala:103)\n\tat org.apache.spark.util.io.ChunkedByteBuffer$$Lambda$1650/1453017789.apply(Unknown Source)\n\tat scala.collection.IndexedSeqOptimized.foreach(IndexedSeqOptimized.scala:36)\n\tat scala.collection.IndexedSeqOptimized.foreach$(IndexedSeqOptimized.scala:33)\n\tat scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:198)\n\tat org.apache.spark.util.io.ChunkedByteBuffer.writeExternal(ChunkedByteBuffer.scala:103)\n\tat org.apache.spark.scheduler.DirectTaskResult.$anonfun$writeExternal$1(TaskResult.scala:60)\n\tat org.apache.spark.scheduler.DirectTaskResult$$Lambda$1648/1417649260.apply$mcV$sp(Unknown Source)\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n\tat org.apache.spark.util.SparkErrorUtils.tryOrIOException(SparkErrorUtils.scala:35)\n\tat org.apache.spark.util.SparkErrorUtils.tryOrIOException$(SparkErrorUtils.scala:33)\n\tat org.apache.spark.util.Utils$.tryOrIOException(Utils.scala:94)\n\tat org.apache.spark.scheduler.DirectTaskResult.writeExternal(TaskResult.scala:59)\n\tat java.io.ObjectOutputStream.writeExternalData(ObjectOutputStream.java:1459)\n\tat java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1430)\n\tat java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1178)\n\tat java.io.ObjectOutputStream.writeObject(ObjectOutputStream.java:348)\n"
     ]
    }
   ],
   "source": [
    "modded_df = modded.toPandas()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-12T11:47:15.537640Z",
     "start_time": "2023-10-12T11:46:52.242650Z"
    }
   },
   "id": "bde49ca363eacaa1"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _c0: string (nullable = true)\n",
      " |-- job_role: string (nullable = true)\n",
      " |-- job_description: string (nullable = true)\n",
      " |-- skills: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- soft_skills: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- responsibility: string (nullable = true)\n",
      " |-- location_name: string (nullable = true)\n",
      " |-- talent_cost: string (nullable = true)\n",
      " |-- currency_code: string (nullable = true)\n",
      " |-- currency: string (nullable = true)\n",
      " |-- experience: string (nullable = true)\n",
      " |-- experience_range: string (nullable = true)\n",
      " |-- ready_for_application: string (nullable = true)\n"
     ]
    }
   ],
   "source": [
    "modded.printSchema()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-12T11:49:30.118787Z",
     "start_time": "2023-10-12T11:49:30.095768Z"
    }
   },
   "id": "23e8135ed9b6aeda"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|skillset                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        |\n",
      "+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|{\"soft_skills\": [\"Rupiah\"], \"skills\": [\"IDR\"]}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  |\n",
      "|{\"soft_skills\": [\"Interpersonal Skills\", \" Organizing\", \" Problem Solving\", \" Integrity\", \" Team Player\", \" Dynamic\", \" Flexible\"], \"skills\": [\"Facility Maintenance\", \" Equipment Maintenance\", \" Preventive Maintenance\", \" Computerized Maintenance Management System (CMMS) Strategy\", \" Building Management System (BMS) Strategy\", \" Operations Management (OM)\", \" Electrical Power System Management\", \" Electrical Equipment Maintenance Planning\", \" Inspection Strategy\", \" Occupational Safety and Health Administration (OSHA) Compliance\", \" Regulatory Compliance\", \" Mechanical Maintenance\", \" Troubleshooting Methodologies\", \" HVAC Maintenance\", \" Risk Assessment\", \" Project Management\"]}|\n",
      "|{\"soft_skills\": [\"Rupiah\"], \"skills\": [\"IDR\"]}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  |\n",
      "|{\"soft_skills\": [\"Interpersonal Skills\", \" Organizing\", \" Problem Solving\", \" Integrity\", \" Team Player\", \" Dynamic\", \" Flexible\"], \"skills\": [\"Facility Maintenance\", \" Equipment Maintenance\", \" Preventive Maintenance\", \" Computerized Maintenance Management System (CMMS) Strategy\", \" Building Management System (BMS) Strategy\", \" Operations Management (OM)\", \" Electrical Power System Management\", \" Electrical Equipment Maintenance Planning\", \" Inspection Strategy\", \" Occupational Safety and Health Administration (OSHA) Compliance\", \" Regulatory Compliance\", \" Mechanical Maintenance\", \" Troubleshooting Methodologies\", \" HVAC Maintenance\", \" Risk Assessment\", \" Project Management\"]}|\n",
      "|{\"soft_skills\": [\"Rupiah\"], \"skills\": [\"IDR\"]}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  |\n",
      "|{\"soft_skills\": [\"Interpersonal Skills\", \" Organizing\", \" Problem Solving\", \" Integrity\", \" Team Player\", \" Dynamic\", \" Flexible\"], \"skills\": [\"Facility Maintenance\", \" Equipment Maintenance\", \" Preventive Maintenance\", \" Computerized Maintenance Management System (CMMS) Strategy\", \" Building Management System (BMS) Strategy\", \" Operations Management (OM)\", \" Electrical Power System Management\", \" Electrical Equipment Maintenance Planning\", \" Inspection Strategy\", \" Occupational Safety and Health Administration (OSHA) Compliance\", \" Regulatory Compliance\", \" Mechanical Maintenance\", \" Troubleshooting Methodologies\", \" HVAC Maintenance\", \" Risk Assessment\", \" Project Management\"]}|\n",
      "|{\"soft_skills\": [\"Rupiah\"], \"skills\": [\"IDR\"]}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  |\n",
      "|{\"soft_skills\": [\"Interpersonal Skills\", \" Organizing\", \" Problem Solving\", \" Integrity\", \" Team Player\", \" Dynamic\", \" Flexible\"], \"skills\": [\"Facility Maintenance\", \" Equipment Maintenance\", \" Preventive Maintenance\", \" Computerized Maintenance Management System (CMMS) Strategy\", \" Building Management System (BMS) Strategy\", \" Operations Management (OM)\", \" Electrical Power System Management\", \" Electrical Equipment Maintenance Planning\", \" Inspection Strategy\", \" Occupational Safety and Health Administration (OSHA) Compliance\", \" Regulatory Compliance\", \" Mechanical Maintenance\", \" Troubleshooting Methodologies\", \" HVAC Maintenance\", \" Risk Assessment\", \" Project Management\"]}|\n",
      "|{\"soft_skills\": [\"Rupiah\"], \"skills\": [\"IDR\"]}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  |\n",
      "|{\"soft_skills\": [\"Interpersonal Skills\", \" Organizing\", \" Problem Solving\", \" Integrity\", \" Team Player\", \" Dynamic\", \" Flexible\"], \"skills\": [\"Facility Maintenance\", \" Equipment Maintenance\", \" Preventive Maintenance\", \" Computerized Maintenance Management System (CMMS) Strategy\", \" Building Management System (BMS) Strategy\", \" Operations Management (OM)\", \" Electrical Power System Management\", \" Electrical Equipment Maintenance Planning\", \" Inspection Strategy\", \" Occupational Safety and Health Administration (OSHA) Compliance\", \" Regulatory Compliance\", \" Mechanical Maintenance\", \" Troubleshooting Methodologies\", \" HVAC Maintenance\", \" Risk Assessment\", \" Project Management\"]}|\n",
      "|{\"soft_skills\": [\"Rupiah\"], \"skills\": [\"IDR\"]}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  |\n",
      "|{\"soft_skills\": [\"Interpersonal Skills\", \" Organizing\", \" Problem Solving\", \" Integrity\", \" Team Player\", \" Dynamic\", \" Flexible\"], \"skills\": [\"Facility Maintenance\", \" Equipment Maintenance\", \" Preventive Maintenance\", \" Computerized Maintenance Management System (CMMS) Strategy\", \" Building Management System (BMS) Strategy\", \" Operations Management (OM)\", \" Electrical Power System Management\", \" Electrical Equipment Maintenance Planning\", \" Inspection Strategy\", \" Occupational Safety and Health Administration (OSHA) Compliance\", \" Regulatory Compliance\", \" Mechanical Maintenance\", \" Troubleshooting Methodologies\", \" HVAC Maintenance\", \" Risk Assessment\", \" Project Management\"]}|\n",
      "|{\"soft_skills\": [\"Rupiah\"], \"skills\": [\"IDR\"]}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  |\n",
      "|{\"soft_skills\": [\"Interpersonal Skills\", \" Organizing\", \" Problem Solving\", \" Integrity\", \" Team Player\", \" Dynamic\", \" Flexible\"], \"skills\": [\"Facility Maintenance\", \" Equipment Maintenance\", \" Preventive Maintenance\", \" Computerized Maintenance Management System (CMMS) Strategy\", \" Building Management System (BMS) Strategy\", \" Operations Management (OM)\", \" Electrical Power System Management\", \" Electrical Equipment Maintenance Planning\", \" Inspection Strategy\", \" Occupational Safety and Health Administration (OSHA) Compliance\", \" Regulatory Compliance\", \" Mechanical Maintenance\", \" Troubleshooting Methodologies\", \" HVAC Maintenance\", \" Risk Assessment\", \" Project Management\"]}|\n",
      "|{\"soft_skills\": [\"Rupiah\"], \"skills\": [\"IDR\"]}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  |\n",
      "|{\"soft_skills\": [\"Interpersonal Skills\", \" Organizing\", \" Problem Solving\", \" Integrity\", \" Team Player\", \" Dynamic\", \" Flexible\"], \"skills\": [\"Facility Maintenance\", \" Equipment Maintenance\", \" Preventive Maintenance\", \" Computerized Maintenance Management System (CMMS) Strategy\", \" Building Management System (BMS) Strategy\", \" Operations Management (OM)\", \" Electrical Power System Management\", \" Electrical Equipment Maintenance Planning\", \" Inspection Strategy\", \" Occupational Safety and Health Administration (OSHA) Compliance\", \" Regulatory Compliance\", \" Mechanical Maintenance\", \" Troubleshooting Methodologies\", \" HVAC Maintenance\", \" Risk Assessment\", \" Project Management\"]}|\n",
      "|{\"soft_skills\": [\"Rupiah\"], \"skills\": [\"IDR\"]}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  |\n",
      "|{\"soft_skills\": [\"Interpersonal Skills\", \" Organizing\", \" Problem Solving\", \" Integrity\", \" Team Player\", \" Dynamic\", \" Flexible\"], \"skills\": [\"Facility Maintenance\", \" Equipment Maintenance\", \" Preventive Maintenance\", \" Computerized Maintenance Management System (CMMS) Strategy\", \" Building Management System (BMS) Strategy\", \" Operations Management (OM)\", \" Electrical Power System Management\", \" Electrical Equipment Maintenance Planning\", \" Inspection Strategy\", \" Occupational Safety and Health Administration (OSHA) Compliance\", \" Regulatory Compliance\", \" Mechanical Maintenance\", \" Troubleshooting Methodologies\", \" HVAC Maintenance\", \" Risk Assessment\", \" Project Management\"]}|\n",
      "|{\"soft_skills\": [\"Rupiah\"], \"skills\": [\"IDR\"]}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  |\n",
      "|{\"soft_skills\": [\"Interpersonal Skills\", \" Organizing\", \" Problem Solving\", \" Integrity\", \" Team Player\", \" Dynamic\", \" Flexible\"], \"skills\": [\"Facility Maintenance\", \" Equipment Maintenance\", \" Preventive Maintenance\", \" Computerized Maintenance Management System (CMMS) Strategy\", \" Building Management System (BMS) Strategy\", \" Operations Management (OM)\", \" Electrical Power System Management\", \" Electrical Equipment Maintenance Planning\", \" Inspection Strategy\", \" Occupational Safety and Health Administration (OSHA) Compliance\", \" Regulatory Compliance\", \" Mechanical Maintenance\", \" Troubleshooting Methodologies\", \" HVAC Maintenance\", \" Risk Assessment\", \" Project Management\"]}|\n",
      "|{\"soft_skills\": [\"Rupiah\"], \"skills\": [\"IDR\"]}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  |\n",
      "|{\"soft_skills\": [\"Interpersonal Skills\", \" Organizing\", \" Problem Solving\", \" Integrity\", \" Team Player\", \" Dynamic\", \" Flexible\"], \"skills\": [\"Facility Maintenance\", \" Equipment Maintenance\", \" Preventive Maintenance\", \" Computerized Maintenance Management System (CMMS) Strategy\", \" Building Management System (BMS) Strategy\", \" Operations Management (OM)\", \" Electrical Power System Management\", \" Electrical Equipment Maintenance Planning\", \" Inspection Strategy\", \" Occupational Safety and Health Administration (OSHA) Compliance\", \" Regulatory Compliance\", \" Mechanical Maintenance\", \" Troubleshooting Methodologies\", \" HVAC Maintenance\", \" Risk Assessment\", \" Project Management\"]}|\n",
      "|{\"soft_skills\": [\"Rupiah\"], \"skills\": [\"IDR\"]}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  |\n",
      "|{\"soft_skills\": [\"Interpersonal Skills\", \" Organizing\", \" Problem Solving\", \" Integrity\", \" Team Player\", \" Dynamic\", \" Flexible\"], \"skills\": [\"Facility Maintenance\", \" Equipment Maintenance\", \" Preventive Maintenance\", \" Computerized Maintenance Management System (CMMS) Strategy\", \" Building Management System (BMS) Strategy\", \" Operations Management (OM)\", \" Electrical Power System Management\", \" Electrical Equipment Maintenance Planning\", \" Inspection Strategy\", \" Occupational Safety and Health Administration (OSHA) Compliance\", \" Regulatory Compliance\", \" Mechanical Maintenance\", \" Troubleshooting Methodologies\", \" HVAC Maintenance\", \" Risk Assessment\", \" Project Management\"]}|\n",
      "|{\"soft_skills\": [\"Rupiah\"], \"skills\": [\"IDR\"]}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  |\n",
      "|{\"soft_skills\": [\"Customer Intimacy\", \" Relationship Management\", \" Communication Skills\", \" Interpersonal Intelligence\", \" Analytical\", \" Collaboration\", \" People Skills\", \" Supportive\", \" Problem Solving\", \" Counselling\"], \"skills\": [\"Benefits & Compensation\", \" Employee Management\", \" Employee Relations\", \" HRIS\", \" Personnel Management\", \" Talent Acquisition\", \" Coaching Employees\"]}                                                                                                                                                                                                                                                                                                          |\n",
      "|{\"soft_skills\": [\"Rupiah\"], \"skills\": [\"IDR\"]}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  |\n",
      "|{\"soft_skills\": [\"Customer Intimacy\", \" Relationship Management\", \" Communication Skills\", \" Interpersonal Intelligence\", \" Analytical\", \" Collaboration\", \" People Skills\", \" Supportive\", \" Problem Solving\", \" Counselling\"], \"skills\": [\"Benefits & Compensation\", \" Employee Management\", \" Employee Relations\", \" HRIS\", \" Personnel Management\", \" Talent Acquisition\", \" Coaching Employees\"]}                                                                                                                                                                                                                                                                                                          |\n",
      "|{\"soft_skills\": [\"Rupiah\"], \"skills\": [\"IDR\"]}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  |\n",
      "|{\"soft_skills\": [\"Customer Intimacy\", \" Relationship Management\", \" Communication Skills\", \" Interpersonal Intelligence\", \" Analytical\", \" Collaboration\", \" People Skills\", \" Supportive\", \" Problem Solving\", \" Counselling\"], \"skills\": [\"Benefits & Compensation\", \" Employee Management\", \" Employee Relations\", \" HRIS\", \" Personnel Management\", \" Talent Acquisition\", \" Coaching Employees\"]}                                                                                                                                                                                                                                                                                                          |\n",
      "|{\"soft_skills\": [\"Rupiah\"], \"skills\": [\"IDR\"]}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  |\n",
      "|{\"soft_skills\": [\"Customer Intimacy\", \" Relationship Management\", \" Communication Skills\", \" Interpersonal Intelligence\", \" Analytical\", \" Collaboration\", \" People Skills\", \" Supportive\", \" Problem Solving\", \" Counselling\"], \"skills\": [\"Benefits & Compensation\", \" Employee Management\", \" Employee Relations\", \" HRIS\", \" Personnel Management\", \" Talent Acquisition\", \" Coaching Employees\"]}                                                                                                                                                                                                                                                                                                          |\n",
      "|{\"soft_skills\": [\"Rupiah\"], \"skills\": [\"IDR\"]}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  |\n",
      "|{\"soft_skills\": [\"Customer Intimacy\", \" Relationship Management\", \" Communication Skills\", \" Interpersonal Intelligence\", \" Analytical\", \" Collaboration\", \" People Skills\", \" Supportive\", \" Problem Solving\", \" Counselling\"], \"skills\": [\"Benefits & Compensation\", \" Employee Management\", \" Employee Relations\", \" HRIS\", \" Personnel Management\", \" Talent Acquisition\", \" Coaching Employees\"]}                                                                                                                                                                                                                                                                                                          |\n",
      "|{\"soft_skills\": [\"Rupiah\"], \"skills\": [\"IDR\"]}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  |\n",
      "|{\"soft_skills\": [\"Customer Intimacy\", \" Relationship Management\", \" Communication Skills\", \" Interpersonal Intelligence\", \" Analytical\", \" Collaboration\", \" People Skills\", \" Supportive\", \" Problem Solving\", \" Counselling\"], \"skills\": [\"Benefits & Compensation\", \" Employee Management\", \" Employee Relations\", \" HRIS\", \" Personnel Management\", \" Talent Acquisition\", \" Coaching Employees\"]}                                                                                                                                                                                                                                                                                                          |\n",
      "|{\"soft_skills\": [\"Rupiah\"], \"skills\": [\"IDR\"]}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  |\n",
      "|{\"soft_skills\": [\"Customer Intimacy\", \" Relationship Management\", \" Communication Skills\", \" Interpersonal Intelligence\", \" Analytical\", \" Collaboration\", \" People Skills\", \" Supportive\", \" Problem Solving\", \" Counselling\"], \"skills\": [\"Benefits & Compensation\", \" Employee Management\", \" Employee Relations\", \" HRIS\", \" Personnel Management\", \" Talent Acquisition\", \" Coaching Employees\"]}                                                                                                                                                                                                                                                                                                          |\n",
      "|{\"soft_skills\": [\"Rupiah\"], \"skills\": [\"IDR\"]}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  |\n",
      "|{\"soft_skills\": [\"Customer Intimacy\", \" Relationship Management\", \" Communication Skills\", \" Interpersonal Intelligence\", \" Analytical\", \" Collaboration\", \" People Skills\", \" Supportive\", \" Problem Solving\", \" Counselling\"], \"skills\": [\"Benefits & Compensation\", \" Employee Management\", \" Employee Relations\", \" HRIS\", \" Personnel Management\", \" Talent Acquisition\", \" Coaching Employees\"]}                                                                                                                                                                                                                                                                                                          |\n",
      "|{\"soft_skills\": [\"Rupiah\"], \"skills\": [\"IDR\"]}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  |\n",
      "|{\"soft_skills\": [\"Customer Intimacy\", \" Relationship Management\", \" Communication Skills\", \" Interpersonal Intelligence\", \" Analytical\", \" Collaboration\", \" People Skills\", \" Supportive\", \" Problem Solving\", \" Counselling\"], \"skills\": [\"Benefits & Compensation\", \" Employee Management\", \" Employee Relations\", \" HRIS\", \" Personnel Management\", \" Talent Acquisition\", \" Coaching Employees\"]}                                                                                                                                                                                                                                                                                                          |\n",
      "|{\"soft_skills\": [\"Rupiah\"], \"skills\": [\"IDR\"]}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  |\n",
      "|{\"soft_skills\": [\"Customer Intimacy\", \" Relationship Management\", \" Communication Skills\", \" Interpersonal Intelligence\", \" Analytical\", \" Collaboration\", \" People Skills\", \" Supportive\", \" Problem Solving\", \" Counselling\"], \"skills\": [\"Benefits & Compensation\", \" Employee Management\", \" Employee Relations\", \" HRIS\", \" Personnel Management\", \" Talent Acquisition\", \" Coaching Employees\"]}                                                                                                                                                                                                                                                                                                          |\n",
      "|{\"soft_skills\": [\"Rupiah\"], \"skills\": [\"IDR\"]}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  |\n",
      "|{\"soft_skills\": [\"Customer Intimacy\", \" Relationship Management\", \" Communication Skills\", \" Interpersonal Intelligence\", \" Analytical\", \" Collaboration\", \" People Skills\", \" Supportive\", \" Problem Solving\", \" Counselling\"], \"skills\": [\"Benefits & Compensation\", \" Employee Management\", \" Employee Relations\", \" HRIS\", \" Personnel Management\", \" Talent Acquisition\", \" Coaching Employees\"]}                                                                                                                                                                                                                                                                                                          |\n",
      "|{\"soft_skills\": [\"Rupiah\"], \"skills\": [\"IDR\"]}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  |\n",
      "|{\"soft_skills\": [\"Customer Intimacy\", \" Relationship Management\", \" Communication Skills\", \" Interpersonal Intelligence\", \" Analytical\", \" Collaboration\", \" People Skills\", \" Supportive\", \" Problem Solving\", \" Counselling\"], \"skills\": [\"Benefits & Compensation\", \" Employee Management\", \" Employee Relations\", \" HRIS\", \" Personnel Management\", \" Talent Acquisition\", \" Coaching Employees\"]}                                                                                                                                                                                                                                                                                                          |\n",
      "|{\"soft_skills\": [\"Rupiah\"], \"skills\": [\"IDR\"]}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  |\n",
      "|{\"soft_skills\": [\"Customer Intimacy\", \" Relationship Management\", \" Communication Skills\", \" Interpersonal Intelligence\", \" Analytical\", \" Collaboration\", \" People Skills\", \" Supportive\", \" Problem Solving\", \" Counselling\"], \"skills\": [\"Benefits & Compensation\", \" Employee Management\", \" Employee Relations\", \" HRIS\", \" Personnel Management\", \" Talent Acquisition\", \" Coaching Employees\"]}                                                                                                                                                                                                                                                                                                          |\n",
      "|{\"soft_skills\": [\"Rupiah\"], \"skills\": [\"IDR\"]}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  |\n",
      "|{\"soft_skills\": [\"Customer Intimacy\", \" Relationship Management\", \" Communication Skills\", \" Interpersonal Intelligence\", \" Analytical\", \" Collaboration\", \" People Skills\", \" Supportive\", \" Problem Solving\", \" Counselling\"], \"skills\": [\"Benefits & Compensation\", \" Employee Management\", \" Employee Relations\", \" HRIS\", \" Personnel Management\", \" Talent Acquisition\", \" Coaching Employees\"]}                                                                                                                                                                                                                                                                                                          |\n",
      "|{\"soft_skills\": [\"Rupiah\"], \"skills\": [\"IDR\"]}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  |\n",
      "|{\"soft_skills\": [\"Customer Intimacy\", \" Relationship Management\", \" Communication Skills\", \" Interpersonal Intelligence\", \" Analytical\", \" Collaboration\", \" People Skills\", \" Supportive\", \" Problem Solving\", \" Counselling\"], \"skills\": [\"Benefits & Compensation\", \" Employee Management\", \" Employee Relations\", \" HRIS\", \" Personnel Management\", \" Talent Acquisition\", \" Coaching Employees\"]}                                                                                                                                                                                                                                                                                                          |\n",
      "|{\"soft_skills\": [\"Rupiah\"], \"skills\": [\"IDR\"]}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  |\n",
      "|{\"soft_skills\": [\"Analytical\", \" Quality Orientation\", \" Challenge Driven\", \" Prioritizing\", \" Presentation Skills\", \" Collaboration\", \" Planning\", \" Problem Solving\", \" Detail Orientation\", \" Critical Thinking\"], \"skills\": [\"Supply Management\", \" Supplier Quality Assurance\", \" SQA\", \" Process Optimization\", \" 5S\", \" Quality Inspection\", \" Quality Cost Analysis\", \" Six Sigma\", \" Quality Control\", \" JD Edwards ERP\", \" Supplier Audit\", \" Advanced Product Quality Planning\", \" APQP\", \" Supplier Quality\", \" Vendor Audit\", \" Supplier Performance\", \" FMEA\", \" Statistical Process Control\", \" SPC\"]}                                                                                           |\n",
      "|{\"soft_skills\": [\"Rupiah\"], \"skills\": [\"IDR\"]}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  |\n",
      "|{\"soft_skills\": [\"Analytical\", \" Quality Orientation\", \" Challenge Driven\", \" Prioritizing\", \" Presentation Skills\", \" Collaboration\", \" Planning\", \" Problem Solving\", \" Detail Orientation\", \" Critical Thinking\"], \"skills\": [\"Supply Management\", \" Supplier Quality Assurance\", \" SQA\", \" Process Optimization\", \" 5S\", \" Quality Inspection\", \" Quality Cost Analysis\", \" Six Sigma\", \" Quality Control\", \" JD Edwards ERP\", \" Supplier Audit\", \" Advanced Product Quality Planning\", \" APQP\", \" Supplier Quality\", \" Vendor Audit\", \" Supplier Performance\", \" FMEA\", \" Statistical Process Control\", \" SPC\"]}                                                                                           |\n",
      "|{\"soft_skills\": [\"Rupiah\"], \"skills\": [\"IDR\"]}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  |\n",
      "|{\"soft_skills\": [\"Analytical\", \" Quality Orientation\", \" Challenge Driven\", \" Prioritizing\", \" Presentation Skills\", \" Collaboration\", \" Planning\", \" Problem Solving\", \" Detail Orientation\", \" Critical Thinking\"], \"skills\": [\"Supply Management\", \" Supplier Quality Assurance\", \" SQA\", \" Process Optimization\", \" 5S\", \" Quality Inspection\", \" Quality Cost Analysis\", \" Six Sigma\", \" Quality Control\", \" JD Edwards ERP\", \" Supplier Audit\", \" Advanced Product Quality Planning\", \" APQP\", \" Supplier Quality\", \" Vendor Audit\", \" Supplier Performance\", \" FMEA\", \" Statistical Process Control\", \" SPC\"]}                                                                                           |\n",
      "|{\"soft_skills\": [\"Rupiah\"], \"skills\": [\"IDR\"]}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  |\n",
      "|{\"soft_skills\": [\"Analytical\", \" Quality Orientation\", \" Challenge Driven\", \" Prioritizing\", \" Presentation Skills\", \" Collaboration\", \" Planning\", \" Problem Solving\", \" Detail Orientation\", \" Critical Thinking\"], \"skills\": [\"Supply Management\", \" Supplier Quality Assurance\", \" SQA\", \" Process Optimization\", \" 5S\", \" Quality Inspection\", \" Quality Cost Analysis\", \" Six Sigma\", \" Quality Control\", \" JD Edwards ERP\", \" Supplier Audit\", \" Advanced Product Quality Planning\", \" APQP\", \" Supplier Quality\", \" Vendor Audit\", \" Supplier Performance\", \" FMEA\", \" Statistical Process Control\", \" SPC\"]}                                                                                           |\n",
      "|{\"soft_skills\": [\"Rupiah\"], \"skills\": [\"IDR\"]}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  |\n",
      "|{\"soft_skills\": [\"Analytical\", \" Quality Orientation\", \" Challenge Driven\", \" Prioritizing\", \" Presentation Skills\", \" Collaboration\", \" Planning\", \" Problem Solving\", \" Detail Orientation\", \" Critical Thinking\"], \"skills\": [\"Supply Management\", \" Supplier Quality Assurance\", \" SQA\", \" Process Optimization\", \" 5S\", \" Quality Inspection\", \" Quality Cost Analysis\", \" Six Sigma\", \" Quality Control\", \" JD Edwards ERP\", \" Supplier Audit\", \" Advanced Product Quality Planning\", \" APQP\", \" Supplier Quality\", \" Vendor Audit\", \" Supplier Performance\", \" FMEA\", \" Statistical Process Control\", \" SPC\"]}                                                                                           |\n",
      "|{\"soft_skills\": [\"Rupiah\"], \"skills\": [\"IDR\"]}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  |\n",
      "|{\"soft_skills\": [\"Analytical\", \" Quality Orientation\", \" Challenge Driven\", \" Prioritizing\", \" Presentation Skills\", \" Collaboration\", \" Planning\", \" Problem Solving\", \" Detail Orientation\", \" Critical Thinking\"], \"skills\": [\"Supply Management\", \" Supplier Quality Assurance\", \" SQA\", \" Process Optimization\", \" 5S\", \" Quality Inspection\", \" Quality Cost Analysis\", \" Six Sigma\", \" Quality Control\", \" JD Edwards ERP\", \" Supplier Audit\", \" Advanced Product Quality Planning\", \" APQP\", \" Supplier Quality\", \" Vendor Audit\", \" Supplier Performance\", \" FMEA\", \" Statistical Process Control\", \" SPC\"]}                                                                                           |\n",
      "|{\"soft_skills\": [\"Rupiah\"], \"skills\": [\"IDR\"]}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  |\n",
      "|{\"soft_skills\": [\"Analytical\", \" Quality Orientation\", \" Challenge Driven\", \" Prioritizing\", \" Presentation Skills\", \" Collaboration\", \" Planning\", \" Problem Solving\", \" Detail Orientation\", \" Critical Thinking\"], \"skills\": [\"Supply Management\", \" Supplier Quality Assurance\", \" SQA\", \" Process Optimization\", \" 5S\", \" Quality Inspection\", \" Quality Cost Analysis\", \" Six Sigma\", \" Quality Control\", \" JD Edwards ERP\", \" Supplier Audit\", \" Advanced Product Quality Planning\", \" APQP\", \" Supplier Quality\", \" Vendor Audit\", \" Supplier Performance\", \" FMEA\", \" Statistical Process Control\", \" SPC\"]}                                                                                           |\n",
      "|{\"soft_skills\": [\"Rupiah\"], \"skills\": [\"IDR\"]}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  |\n",
      "|{\"soft_skills\": [\"Analytical\", \" Quality Orientation\", \" Challenge Driven\", \" Prioritizing\", \" Presentation Skills\", \" Collaboration\", \" Planning\", \" Problem Solving\", \" Detail Orientation\", \" Critical Thinking\"], \"skills\": [\"Supply Management\", \" Supplier Quality Assurance\", \" SQA\", \" Process Optimization\", \" 5S\", \" Quality Inspection\", \" Quality Cost Analysis\", \" Six Sigma\", \" Quality Control\", \" JD Edwards ERP\", \" Supplier Audit\", \" Advanced Product Quality Planning\", \" APQP\", \" Supplier Quality\", \" Vendor Audit\", \" Supplier Performance\", \" FMEA\", \" Statistical Process Control\", \" SPC\"]}                                                                                           |\n",
      "|{\"soft_skills\": [\"Rupiah\"], \"skills\": [\"IDR\"]}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  |\n",
      "|{\"soft_skills\": [\"Analytical\", \" Quality Orientation\", \" Challenge Driven\", \" Prioritizing\", \" Presentation Skills\", \" Collaboration\", \" Planning\", \" Problem Solving\", \" Detail Orientation\", \" Critical Thinking\"], \"skills\": [\"Supply Management\", \" Supplier Quality Assurance\", \" SQA\", \" Process Optimization\", \" 5S\", \" Quality Inspection\", \" Quality Cost Analysis\", \" Six Sigma\", \" Quality Control\", \" JD Edwards ERP\", \" Supplier Audit\", \" Advanced Product Quality Planning\", \" APQP\", \" Supplier Quality\", \" Vendor Audit\", \" Supplier Performance\", \" FMEA\", \" Statistical Process Control\", \" SPC\"]}                                                                                           |\n",
      "|{\"soft_skills\": [\"Rupiah\"], \"skills\": [\"IDR\"]}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  |\n",
      "|{\"soft_skills\": [\"Analytical\", \" Quality Orientation\", \" Challenge Driven\", \" Prioritizing\", \" Presentation Skills\", \" Collaboration\", \" Planning\", \" Problem Solving\", \" Detail Orientation\", \" Critical Thinking\"], \"skills\": [\"Supply Management\", \" Supplier Quality Assurance\", \" SQA\", \" Process Optimization\", \" 5S\", \" Quality Inspection\", \" Quality Cost Analysis\", \" Six Sigma\", \" Quality Control\", \" JD Edwards ERP\", \" Supplier Audit\", \" Advanced Product Quality Planning\", \" APQP\", \" Supplier Quality\", \" Vendor Audit\", \" Supplier Performance\", \" FMEA\", \" Statistical Process Control\", \" SPC\"]}                                                                                           |\n",
      "|{\"soft_skills\": [\"Rupiah\"], \"skills\": [\"IDR\"]}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  |\n",
      "|{\"soft_skills\": [\"Analytical\", \" Quality Orientation\", \" Challenge Driven\", \" Prioritizing\", \" Presentation Skills\", \" Collaboration\", \" Planning\", \" Problem Solving\", \" Detail Orientation\", \" Critical Thinking\"], \"skills\": [\"Supply Management\", \" Supplier Quality Assurance\", \" SQA\", \" Process Optimization\", \" 5S\", \" Quality Inspection\", \" Quality Cost Analysis\", \" Six Sigma\", \" Quality Control\", \" JD Edwards ERP\", \" Supplier Audit\", \" Advanced Product Quality Planning\", \" APQP\", \" Supplier Quality\", \" Vendor Audit\", \" Supplier Performance\", \" FMEA\", \" Statistical Process Control\", \" SPC\"]}                                                                                           |\n",
      "|{\"soft_skills\": [\"Rupiah\"], \"skills\": [\"IDR\"]}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  |\n",
      "|{\"soft_skills\": [\"Analytical\", \" Quality Orientation\", \" Challenge Driven\", \" Prioritizing\", \" Presentation Skills\", \" Collaboration\", \" Planning\", \" Problem Solving\", \" Detail Orientation\", \" Critical Thinking\"], \"skills\": [\"Supply Management\", \" Supplier Quality Assurance\", \" SQA\", \" Process Optimization\", \" 5S\", \" Quality Inspection\", \" Quality Cost Analysis\", \" Six Sigma\", \" Quality Control\", \" JD Edwards ERP\", \" Supplier Audit\", \" Advanced Product Quality Planning\", \" APQP\", \" Supplier Quality\", \" Vendor Audit\", \" Supplier Performance\", \" FMEA\", \" Statistical Process Control\", \" SPC\"]}                                                                                           |\n",
      "|{\"soft_skills\": [\"Rupiah\"], \"skills\": [\"IDR\"]}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  |\n",
      "|{\"soft_skills\": [\"Analytical\", \" Quality Orientation\", \" Challenge Driven\", \" Prioritizing\", \" Presentation Skills\", \" Collaboration\", \" Planning\", \" Problem Solving\", \" Detail Orientation\", \" Critical Thinking\"], \"skills\": [\"Supply Management\", \" Supplier Quality Assurance\", \" SQA\", \" Process Optimization\", \" 5S\", \" Quality Inspection\", \" Quality Cost Analysis\", \" Six Sigma\", \" Quality Control\", \" JD Edwards ERP\", \" Supplier Audit\", \" Advanced Product Quality Planning\", \" APQP\", \" Supplier Quality\", \" Vendor Audit\", \" Supplier Performance\", \" FMEA\", \" Statistical Process Control\", \" SPC\"]}                                                                                           |\n",
      "|{\"soft_skills\": [\"Rupiah\"], \"skills\": [\"IDR\"]}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  |\n",
      "|{\"soft_skills\": [\"Analytical\", \" Quality Orientation\", \" Challenge Driven\", \" Prioritizing\", \" Presentation Skills\", \" Collaboration\", \" Planning\", \" Problem Solving\", \" Detail Orientation\", \" Critical Thinking\"], \"skills\": [\"Supply Management\", \" Supplier Quality Assurance\", \" SQA\", \" Process Optimization\", \" 5S\", \" Quality Inspection\", \" Quality Cost Analysis\", \" Six Sigma\", \" Quality Control\", \" JD Edwards ERP\", \" Supplier Audit\", \" Advanced Product Quality Planning\", \" APQP\", \" Supplier Quality\", \" Vendor Audit\", \" Supplier Performance\", \" FMEA\", \" Statistical Process Control\", \" SPC\"]}                                                                                           |\n",
      "|{\"soft_skills\": [\"Rupiah\"], \"skills\": [\"IDR\"]}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  |\n",
      "|{\"soft_skills\": [\"Logical Thinking\", \" Problem Solving\", \" Proactivity\", \" Result Oriented\", \" Team Oriented\", \" Flexibility\", \" Planning\", \" Quality Orientation\", \" Supportive\", \" Accountability\"], \"skills\": [\"Equipment Installation\", \" Fault Diagnosis\", \" Preventive Maintenance\", \" Equipment Maintenance\", \" Electrical Diagnosis\", \" Plant Maintenance\", \" Equipment Calibration\", \" Effective Fault Resolution\", \" Safety Standards\", \" Electrical Drawings\"]}                                                                                                                                                                                                                                      |\n",
      "|{\"soft_skills\": [\"Rupiah\"], \"skills\": [\"IDR\"]}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  |\n",
      "|{\"soft_skills\": [\"Logical Thinking\", \" Problem Solving\", \" Proactivity\", \" Result Oriented\", \" Team Oriented\", \" Flexibility\", \" Planning\", \" Quality Orientation\", \" Supportive\", \" Accountability\"], \"skills\": [\"Equipment Installation\", \" Fault Diagnosis\", \" Preventive Maintenance\", \" Equipment Maintenance\", \" Electrical Diagnosis\", \" Plant Maintenance\", \" Equipment Calibration\", \" Effective Fault Resolution\", \" Safety Standards\", \" Electrical Drawings\"]}                                                                                                                                                                                                                                      |\n",
      "|{\"soft_skills\": [\"Rupiah\"], \"skills\": [\"IDR\"]}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  |\n",
      "|{\"soft_skills\": [\"Logical Thinking\", \" Problem Solving\", \" Proactivity\", \" Result Oriented\", \" Team Oriented\", \" Flexibility\", \" Planning\", \" Quality Orientation\", \" Supportive\", \" Accountability\"], \"skills\": [\"Equipment Installation\", \" Fault Diagnosis\", \" Preventive Maintenance\", \" Equipment Maintenance\", \" Electrical Diagnosis\", \" Plant Maintenance\", \" Equipment Calibration\", \" Effective Fault Resolution\", \" Safety Standards\", \" Electrical Drawings\"]}                                                                                                                                                                                                                                      |\n",
      "|{\"soft_skills\": [\"Rupiah\"], \"skills\": [\"IDR\"]}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  |\n",
      "|{\"soft_skills\": [\"Logical Thinking\", \" Problem Solving\", \" Proactivity\", \" Result Oriented\", \" Team Oriented\", \" Flexibility\", \" Planning\", \" Quality Orientation\", \" Supportive\", \" Accountability\"], \"skills\": [\"Equipment Installation\", \" Fault Diagnosis\", \" Preventive Maintenance\", \" Equipment Maintenance\", \" Electrical Diagnosis\", \" Plant Maintenance\", \" Equipment Calibration\", \" Effective Fault Resolution\", \" Safety Standards\", \" Electrical Drawings\"]}                                                                                                                                                                                                                                      |\n",
      "|{\"soft_skills\": [\"Rupiah\"], \"skills\": [\"IDR\"]}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  |\n",
      "|{\"soft_skills\": [\"Logical Thinking\", \" Problem Solving\", \" Proactivity\", \" Result Oriented\", \" Team Oriented\", \" Flexibility\", \" Planning\", \" Quality Orientation\", \" Supportive\", \" Accountability\"], \"skills\": [\"Equipment Installation\", \" Fault Diagnosis\", \" Preventive Maintenance\", \" Equipment Maintenance\", \" Electrical Diagnosis\", \" Plant Maintenance\", \" Equipment Calibration\", \" Effective Fault Resolution\", \" Safety Standards\", \" Electrical Drawings\"]}                                                                                                                                                                                                                                      |\n",
      "|{\"soft_skills\": [\"Rupiah\"], \"skills\": [\"IDR\"]}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  |\n",
      "|{\"soft_skills\": [\"Logical Thinking\", \" Problem Solving\", \" Proactivity\", \" Result Oriented\", \" Team Oriented\", \" Flexibility\", \" Planning\", \" Quality Orientation\", \" Supportive\", \" Accountability\"], \"skills\": [\"Equipment Installation\", \" Fault Diagnosis\", \" Preventive Maintenance\", \" Equipment Maintenance\", \" Electrical Diagnosis\", \" Plant Maintenance\", \" Equipment Calibration\", \" Effective Fault Resolution\", \" Safety Standards\", \" Electrical Drawings\"]}                                                                                                                                                                                                                                      |\n",
      "|{\"soft_skills\": [\"Rupiah\"], \"skills\": [\"IDR\"]}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  |\n",
      "|{\"soft_skills\": [\"Logical Thinking\", \" Problem Solving\", \" Proactivity\", \" Result Oriented\", \" Team Oriented\", \" Flexibility\", \" Planning\", \" Quality Orientation\", \" Supportive\", \" Accountability\"], \"skills\": [\"Equipment Installation\", \" Fault Diagnosis\", \" Preventive Maintenance\", \" Equipment Maintenance\", \" Electrical Diagnosis\", \" Plant Maintenance\", \" Equipment Calibration\", \" Effective Fault Resolution\", \" Safety Standards\", \" Electrical Drawings\"]}                                                                                                                                                                                                                                      |\n",
      "|{\"soft_skills\": [\"Rupiah\"], \"skills\": [\"IDR\"]}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  |\n",
      "|{\"soft_skills\": [\"Logical Thinking\", \" Problem Solving\", \" Proactivity\", \" Result Oriented\", \" Team Oriented\", \" Flexibility\", \" Planning\", \" Quality Orientation\", \" Supportive\", \" Accountability\"], \"skills\": [\"Equipment Installation\", \" Fault Diagnosis\", \" Preventive Maintenance\", \" Equipment Maintenance\", \" Electrical Diagnosis\", \" Plant Maintenance\", \" Equipment Calibration\", \" Effective Fault Resolution\", \" Safety Standards\", \" Electrical Drawings\"]}                                                                                                                                                                                                                                      |\n",
      "|{\"soft_skills\": [\"Rupiah\"], \"skills\": [\"IDR\"]}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  |\n",
      "|{\"soft_skills\": [\"Logical Thinking\", \" Problem Solving\", \" Proactivity\", \" Result Oriented\", \" Team Oriented\", \" Flexibility\", \" Planning\", \" Quality Orientation\", \" Supportive\", \" Accountability\"], \"skills\": [\"Equipment Installation\", \" Fault Diagnosis\", \" Preventive Maintenance\", \" Equipment Maintenance\", \" Electrical Diagnosis\", \" Plant Maintenance\", \" Equipment Calibration\", \" Effective Fault Resolution\", \" Safety Standards\", \" Electrical Drawings\"]}                                                                                                                                                                                                                                      |\n",
      "+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pyspark.sql.functions as f\n",
    "def makejsonstring(soft_skills,skills):\n",
    "    return json.dumps({\"soft_skills\":soft_skills,\"skills\":skills})\n",
    "udf_makejsonstring = f.udf(makejsonstring)\n",
    "modded.filter(f.col(\"soft_skills\").isNotNull()).withColumn(\"skillset\", udf_makejsonstring(\"soft_skills\",\"skills\")).select(\"skillset\").show(100,False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-12T11:54:56.669619Z",
     "start_time": "2023-10-12T11:54:55.626247Z"
    }
   },
   "id": "b581dc72ed8c9494"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "skillset = modded.withColumn(\"skillset\", udf_makejsonstring(\"soft_skills\",\"skills\"))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-12T11:56:06.917514Z",
     "start_time": "2023-10-12T11:56:06.820707Z"
    }
   },
   "id": "2143ff15923bef9a"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 3:===================================================>       (7 + 1) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+\n",
      "|skillset_length|\n",
      "+---------------+\n",
      "|37             |\n",
      "|37             |\n",
      "|37             |\n",
      "|37             |\n",
      "|37             |\n",
      "|37             |\n",
      "|37             |\n",
      "|37             |\n",
      "|37             |\n",
      "|37             |\n",
      "|37             |\n",
      "|37             |\n",
      "|37             |\n",
      "|37             |\n",
      "|37             |\n",
      "|37             |\n",
      "|37             |\n",
      "|37             |\n",
      "|37             |\n",
      "|37             |\n",
      "|37             |\n",
      "|37             |\n",
      "|37             |\n",
      "|37             |\n",
      "|37             |\n",
      "|37             |\n",
      "|37             |\n",
      "|37             |\n",
      "|37             |\n",
      "|37             |\n",
      "|37             |\n",
      "|37             |\n",
      "|37             |\n",
      "|37             |\n",
      "|37             |\n",
      "|37             |\n",
      "|37             |\n",
      "|37             |\n",
      "|37             |\n",
      "|37             |\n",
      "|37             |\n",
      "|37             |\n",
      "|37             |\n",
      "|37             |\n",
      "|37             |\n",
      "|37             |\n",
      "|37             |\n",
      "|37             |\n",
      "|37             |\n",
      "|37             |\n",
      "|37             |\n",
      "|37             |\n",
      "|37             |\n",
      "|37             |\n",
      "|37             |\n",
      "|37             |\n",
      "|37             |\n",
      "|37             |\n",
      "|37             |\n",
      "|37             |\n",
      "|37             |\n",
      "|37             |\n",
      "|37             |\n",
      "|37             |\n",
      "|37             |\n",
      "|37             |\n",
      "|37             |\n",
      "|37             |\n",
      "|37             |\n",
      "|37             |\n",
      "|37             |\n",
      "|37             |\n",
      "|37             |\n",
      "|37             |\n",
      "|37             |\n",
      "|37             |\n",
      "|37             |\n",
      "|37             |\n",
      "|37             |\n",
      "|37             |\n",
      "|37             |\n",
      "|37             |\n",
      "|37             |\n",
      "|37             |\n",
      "|37             |\n",
      "|37             |\n",
      "|37             |\n",
      "|37             |\n",
      "|37             |\n",
      "|37             |\n",
      "|37             |\n",
      "|37             |\n",
      "|37             |\n",
      "|37             |\n",
      "|37             |\n",
      "|37             |\n",
      "|37             |\n",
      "|37             |\n",
      "|37             |\n",
      "|37             |\n",
      "+---------------+\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "skillset.withColumn(\"skillset_length\", f.length(\"skillset\")).select(\"skillset_length\").orderBy(f.col(\"skillset\").desc()).show(100,False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-12T11:57:18.834707Z",
     "start_time": "2023-10-12T11:56:45.508031Z"
    }
   },
   "id": "38df89ba665ae3dc"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "skillset = modded.withColumn(\"skillset\", udf_makejsonstring(\"soft_skills\",\"skills\")).drop(\"skills\",\"soft_skills\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-12T11:58:21.377188Z",
     "start_time": "2023-10-12T11:58:21.072085Z"
    }
   },
   "id": "b21ecb0dab5aa3df"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "skillset.drop(\"_c0\").repartition(1).write.format(\"csv\").mode(\"overwrite\").save(\"/Users/eashvrudhula/PycharmProjects/Hackathon3/PostgresData/hackathon_data_modified_csv_new\",header=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-12T12:06:54.937764Z",
     "start_time": "2023-10-12T12:05:43.526098Z"
    }
   },
   "id": "75076c3ce8106a5e"
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _c0: string (nullable = true)\n",
      " |-- job_role: string (nullable = true)\n",
      " |-- job_description: string (nullable = true)\n",
      " |-- responsibility: string (nullable = true)\n",
      " |-- location_name: string (nullable = true)\n",
      " |-- talent_cost: string (nullable = true)\n",
      " |-- currency_code: string (nullable = true)\n",
      " |-- currency: string (nullable = true)\n",
      " |-- experience: string (nullable = true)\n",
      " |-- experience_range: string (nullable = true)\n",
      " |-- ready_for_application: string (nullable = true)\n",
      " |-- skillset: string (nullable = true)\n"
     ]
    }
   ],
   "source": [
    "skillset.printSchema()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-12T12:08:06.897369Z",
     "start_time": "2023-10-12T12:08:06.790934Z"
    }
   },
   "id": "f61cced0998fc5fd"
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "skillset = spark.read.format(\"csv\").load(\"/Users/eashvrudhula/PycharmProjects/Hackathon3/PostgresData/hackathon_data_modified_csv_new\",header=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-12T12:19:51.655716Z",
     "start_time": "2023-10-12T12:19:50.645902Z"
    }
   },
   "id": "e35b5a598c5bd41e"
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- job_role: string (nullable = true)\n",
      " |-- job_description: string (nullable = true)\n",
      " |-- responsibility: string (nullable = true)\n",
      " |-- location_name: string (nullable = true)\n",
      " |-- talent_cost: string (nullable = true)\n",
      " |-- currency_code: string (nullable = true)\n",
      " |-- currency: string (nullable = true)\n",
      " |-- experience: string (nullable = true)\n",
      " |-- experience_range: string (nullable = true)\n",
      " |-- ready_for_application: string (nullable = true)\n",
      " |-- skillset: string (nullable = true)\n"
     ]
    }
   ],
   "source": [
    "skillset.printSchema()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-12T12:20:11.491298Z",
     "start_time": "2023-10-12T12:20:11.461877Z"
    }
   },
   "id": "78d5bf367582dc19"
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "properties = {\n",
    "            \"user\": \"postgres\",\n",
    "            \"password\": \"$Eash1312#\",\n",
    "            \"driver\": \"org.postgresql.Driver\"\n",
    "}\n",
    "driver = \"postgresql\"\n",
    "hostname = \"localhost\"\n",
    "port = \"5432\"\n",
    "database = \"postgres\"\n",
    "username = \"postgres\"\n",
    "password = \"$Eash1312#\"\n",
    "url = \"jdbc:{0}://{1}:{2}/{3}?user={4}&password={5}\".format(driver, hostname, port, database, username,\n",
    "                                                                    password)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-12T12:21:02.623984Z",
     "start_time": "2023-10-12T12:21:02.613734Z"
    }
   },
   "id": "d31e8f094692d98"
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------+\n",
      "|talent_cost                 |\n",
      "+----------------------------+\n",
      "|False                       |\n",
      "|True                        |\n",
      "|False                       |\n",
      "|False                       |\n",
      "|False                       |\n",
      "|False                       |\n",
      "|True                        |\n",
      "|False                       |\n",
      "|False                       |\n",
      "|False                       |\n",
      "|True                        |\n",
      "|True                        |\n",
      "|True                        |\n",
      "|False                       |\n",
      "|False                       |\n",
      "|False                       |\n",
      "|False                       |\n",
      "|True                        |\n",
      "|False                       |\n",
      "|True                        |\n",
      "|False                       |\n",
      "|False                       |\n",
      "|False                       |\n",
      "|False                       |\n",
      "|True                        |\n",
      "|False                       |\n",
      "|False                       |\n",
      "|True                        |\n",
      "|False                       |\n",
      "|False                       |\n",
      "|True                        |\n",
      "|False                       |\n",
      "|False                       |\n",
      "|False                       |\n",
      "|False                       |\n",
      "|False                       |\n",
      "|False                       |\n",
      "|True                        |\n",
      "|False                       |\n",
      "|False                       |\n",
      "|True                        |\n",
      "|False                       |\n",
      "|True                        |\n",
      "|True                        |\n",
      "|True                        |\n",
      "|False                       |\n",
      "|True                        |\n",
      "|False                       |\n",
      "|False                       |\n",
      "|False                       |\n",
      "|False                       |\n",
      "|False                       |\n",
      "|False                       |\n",
      "|False                       |\n",
      "|False                       |\n",
      "|False                       |\n",
      "|False                       |\n",
      "|supportive of business goals|\n",
      "|False                       |\n",
      "|supportive of business goals|\n",
      "|True                        |\n",
      "|supportive of business goals|\n",
      "|False                       |\n",
      "|supportive of business goals|\n",
      "|True                        |\n",
      "|supportive of business goals|\n",
      "|False                       |\n",
      "|supportive of business goals|\n",
      "|False                       |\n",
      "|supportive of business goals|\n",
      "|False                       |\n",
      "|supportive of business goals|\n",
      "|False                       |\n",
      "|supportive of business goals|\n",
      "|True                        |\n",
      "|supportive of business goals|\n",
      "|True                        |\n",
      "|supportive of business goals|\n",
      "|True                        |\n",
      "|supportive of business goals|\n",
      "|False                       |\n",
      "|supportive of business goals|\n",
      "|True                        |\n",
      "|supportive of business goals|\n",
      "|False                       |\n",
      "|False                       |\n",
      "|False                       |\n",
      "|False                       |\n",
      "|False                       |\n",
      "|False                       |\n",
      "|False                       |\n",
      "|False                       |\n",
      "|False                       |\n",
      "|False                       |\n",
      "|False                       |\n",
      "|True                        |\n",
      "|False                       |\n",
      "|False                       |\n",
      "|False                       |\n",
      "|False                       |\n",
      "+----------------------------+\n"
     ]
    }
   ],
   "source": [
    "skillset.select(\"talent_cost\").filter(f.col(\"talent_cost\").isNotNull()).show(100,False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-12T12:23:07.996733Z",
     "start_time": "2023-10-12T12:23:06.816890Z"
    }
   },
   "id": "83b852337a6cbb5f"
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- job_role: string (nullable = true)\n",
      " |-- job_description: string (nullable = true)\n",
      " |-- responsibility: string (nullable = true)\n",
      " |-- location_name: string (nullable = true)\n",
      " |-- talent_cost: string (nullable = true)\n",
      " |-- currency_code: string (nullable = true)\n",
      " |-- currency: string (nullable = true)\n",
      " |-- experience: string (nullable = true)\n",
      " |-- experience_range: string (nullable = true)\n",
      " |-- ready_for_application: string (nullable = true)\n",
      " |-- skillset: string (nullable = true)\n"
     ]
    }
   ],
   "source": [
    "skillset.printSchema()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-12T12:24:06.743629Z",
     "start_time": "2023-10-12T12:24:06.712028Z"
    }
   },
   "id": "c017e18eb4dc63fd"
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [
    "hackathon_data_og = spark.read.format(\"csv\").load(\"/Users/eashvrudhula/PycharmProjects/Hackathon3/PostgresData/hackathon_data.csv\",header=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-12T12:24:44.187063Z",
     "start_time": "2023-10-12T12:24:43.292029Z"
    }
   },
   "id": "4cdc94cf8b53e652"
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|talent_cost                                                                                                                                              |\n",
      "+---------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|True                                                                                                                                                     |\n",
      "|True                                                                                                                                                     |\n",
      "|True                                                                                                                                                     |\n",
      "|True                                                                                                                                                     |\n",
      "|False                                                                                                                                                    |\n",
      "|True                                                                                                                                                     |\n",
      "|True                                                                                                                                                     |\n",
      "|True                                                                                                                                                     |\n",
      "|False                                                                                                                                                    |\n",
      "|True                                                                                                                                                     |\n",
      "|False                                                                                                                                                    |\n",
      "|False                                                                                                                                                    |\n",
      "|True                                                                                                                                                     |\n",
      "|False                                                                                                                                                    |\n",
      "|True                                                                                                                                                     |\n",
      "|76800.0                                                                                                                                                  |\n",
      "|46080.0                                                                                                                                                  |\n",
      "|False                                                                                                                                                    |\n",
      "|True                                                                                                                                                     |\n",
      "|True                                                                                                                                                     |\n",
      "|True                                                                                                                                                     |\n",
      "|False                                                                                                                                                    |\n",
      "|False                                                                                                                                                    |\n",
      "|True                                                                                                                                                     |\n",
      "|True                                                                                                                                                     |\n",
      "|False                                                                                                                                                    |\n",
      "|True                                                                                                                                                     |\n",
      "|False                                                                                                                                                    |\n",
      "|False                                                                                                                                                    |\n",
      "|True                                                                                                                                                     |\n",
      "|True                                                                                                                                                     |\n",
      "|True                                                                                                                                                     |\n",
      "|True                                                                                                                                                     |\n",
      "|False                                                                                                                                                    |\n",
      "|True                                                                                                                                                     |\n",
      "|True                                                                                                                                                     |\n",
      "|True                                                                                                                                                     |\n",
      "|False                                                                                                                                                    |\n",
      "|True                                                                                                                                                     |\n",
      "|True                                                                                                                                                     |\n",
      "|True                                                                                                                                                     |\n",
      "|True                                                                                                                                                     |\n",
      "|True                                                                                                                                                     |\n",
      "|True                                                                                                                                                     |\n",
      "|False                                                                                                                                                    |\n",
      "|True                                                                                                                                                     |\n",
      "|True                                                                                                                                                     |\n",
      "|False                                                                                                                                                    |\n",
      "|False                                                                                                                                                    |\n",
      "|True                                                                                                                                                     |\n",
      "|False                                                                                                                                                    |\n",
      "|True                                                                                                                                                     |\n",
      "|False                                                                                                                                                    |\n",
      "|True                                                                                                                                                     |\n",
      "|False                                                                                                                                                    |\n",
      "|True                                                                                                                                                     |\n",
      "|False                                                                                                                                                    |\n",
      "|True                                                                                                                                                     |\n",
      "|False                                                                                                                                                    |\n",
      "|True                                                                                                                                                     |\n",
      "|True                                                                                                                                                     |\n",
      "|True                                                                                                                                                     |\n",
      "|True                                                                                                                                                     |\n",
      "|True                                                                                                                                                     |\n",
      "|True                                                                                                                                                     |\n",
      "|True                                                                                                                                                     |\n",
      "|True                                                                                                                                                     |\n",
      "|True                                                                                                                                                     |\n",
      "|False                                                                                                                                                    |\n",
      "|True                                                                                                                                                     |\n",
      "|False                                                                                                                                                    |\n",
      "|True                                                                                                                                                     |\n",
      "|False                                                                                                                                                    |\n",
      "|True                                                                                                                                                     |\n",
      "|True                                                                                                                                                     |\n",
      "|False                                                                                                                                                    |\n",
      "|False                                                                                                                                                    |\n",
      "|True                                                                                                                                                     |\n",
      "|True                                                                                                                                                     |\n",
      "|False                                                                                                                                                    |\n",
      "| answering any questions                                                                                                                                 |\n",
      "|False                                                                                                                                                    |\n",
      "| answering any questions                                                                                                                                 |\n",
      "|True                                                                                                                                                     |\n",
      "|Negotiation; Analytical; Client Handling; Manageability; Self Motivation; Strategist; Challenge Driven; Communication Skills; Leadership; Business Acumen|\n",
      "|False                                                                                                                                                    |\n",
      "|Negotiation; Analytical; Client Handling; Manageability; Self Motivation; Strategist; Challenge Driven; Communication Skills; Leadership; Business Acumen|\n",
      "|True                                                                                                                                                     |\n",
      "|True                                                                                                                                                     |\n",
      "|True                                                                                                                                                     |\n",
      "|True                                                                                                                                                     |\n",
      "|True                                                                                                                                                     |\n",
      "|False                                                                                                                                                    |\n",
      "|True                                                                                                                                                     |\n",
      "| and best practices for internal teams and partners;                                                                                                     |\n",
      "|True                                                                                                                                                     |\n",
      "|True                                                                                                                                                     |\n",
      "|True                                                                                                                                                     |\n",
      "|True                                                                                                                                                     |\n",
      "|True                                                                                                                                                     |\n",
      "+---------------------------------------------------------------------------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "hackathon_data_og.select(\"talent_cost\").filter(f.col(\"talent_cost\").isNotNull()).show(100,False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-12T12:25:07.500478Z",
     "start_time": "2023-10-12T12:25:06.673994Z"
    }
   },
   "id": "7a58fbed16fd4c83"
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [],
   "source": [
    "hackdata = spark.read.parquet(\"/Users/eashvrudhula/PycharmProjects/Hackathon3/HackData/part-00000-7ffe30f6-3f37-461b-9f30-5b3f9f1e5600-c000.snappy.parquet\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-12T12:50:34.886320Z",
     "start_time": "2023-10-12T12:50:33.944704Z"
    }
   },
   "id": "a45fa4bc8a1ddbde"
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- job_role: string (nullable = true)\n",
      " |-- job_description: string (nullable = true)\n",
      " |-- skills: string (nullable = true)\n",
      " |-- soft_skills: string (nullable = true)\n",
      " |-- responsibility: string (nullable = true)\n",
      " |-- location_name: string (nullable = true)\n",
      " |-- talent_cost: double (nullable = true)\n",
      " |-- currency_code: string (nullable = true)\n",
      " |-- currency: string (nullable = true)\n",
      " |-- experience: double (nullable = true)\n",
      " |-- experience_range: string (nullable = true)\n"
     ]
    }
   ],
   "source": [
    "hackdata.printSchema()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-12T12:50:38.142925Z",
     "start_time": "2023-10-12T12:50:38.082595Z"
    }
   },
   "id": "f202332a3daa73c8"
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|talent_cost         |\n",
      "+--------------------+\n",
      "|219880.34011299434  |\n",
      "|127928.70406779661  |\n",
      "|1.2655719215368384E7|\n",
      "|61797.6             |\n",
      "|72000.0             |\n",
      "|120000.0            |\n",
      "|95000.0             |\n",
      "|57000.0             |\n",
      "|88200.0             |\n",
      "|1.177922353526969E7 |\n",
      "|1.2302447536025774E7|\n",
      "|1.2898235449295474E7|\n",
      "|120000.0            |\n",
      "|72000.0             |\n",
      "|56160.0             |\n",
      "|9057122.027686495   |\n",
      "|216000.0            |\n",
      "|129600.0            |\n",
      "|43200.0             |\n",
      "|72000.0             |\n",
      "|145497.6            |\n",
      "|242496.0            |\n",
      "|108000.0            |\n",
      "|64800.0             |\n",
      "|86400.0             |\n",
      "|144000.0            |\n",
      "|121998.0            |\n",
      "|73198.8             |\n",
      "|78300.0             |\n",
      "|130500.0            |\n",
      "|60000.0             |\n",
      "|36000.0             |\n",
      "|1.1102278614583446E7|\n",
      "|1.1639824440177742E7|\n",
      "|1.0629658394922385E7|\n",
      "|216000.0            |\n",
      "|129600.0            |\n",
      "|100000.0            |\n",
      "|60000.0             |\n",
      "|50400.0             |\n",
      "|84000.0             |\n",
      "|270480.0            |\n",
      "|450800.0            |\n",
      "|106935.59999999999  |\n",
      "|114881.99999999997  |\n",
      "|1.902702169172849E7 |\n",
      "|43200.0             |\n",
      "|72000.0             |\n",
      "|60000.0             |\n",
      "|36000.0             |\n",
      "|82800.0             |\n",
      "|138000.0            |\n",
      "|84780.0             |\n",
      "|141300.0            |\n",
      "|72000.0             |\n",
      "|7679362.4782503145  |\n",
      "|43200.0             |\n",
      "|216000.0            |\n",
      "|129600.0            |\n",
      "|50400.0             |\n",
      "|84000.0             |\n",
      "|192000.0            |\n",
      "|115200.0            |\n",
      "|96000.0             |\n",
      "|57600.0             |\n",
      "|194400.0            |\n",
      "|324000.0            |\n",
      "|84000.0             |\n",
      "|79006.65            |\n",
      "|97200.0             |\n",
      "|58320.0             |\n",
      "|67596.0             |\n",
      "|40557.6             |\n",
      "|90300.0             |\n",
      "|150500.0            |\n",
      "|115200.0            |\n",
      "|192000.0            |\n",
      "|54000.0             |\n",
      "|90000.0             |\n",
      "|53464.5             |\n",
      "|89107.5             |\n",
      "|194399.99999999997  |\n",
      "|323999.99999999994  |\n",
      "|174000.0            |\n",
      "|104400.0            |\n",
      "|151280.50073637703  |\n",
      "|90768.30044182621   |\n",
      "|73160.04779725063   |\n",
      "|72000.0             |\n",
      "|43200.0             |\n",
      "|240000.0            |\n",
      "|144000.0            |\n",
      "|96000.0             |\n",
      "|57600.0             |\n",
      "|89753.80298507462   |\n",
      "|123379.34328358209  |\n",
      "|24948.0             |\n",
      "|41580.0             |\n",
      "|180000.0            |\n",
      "|300000.0            |\n",
      "+--------------------+\n"
     ]
    }
   ],
   "source": [
    "hackdata.select(\"talent_cost\").filter(f.col(\"talent_cost\").isNotNull()).show(100,False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-12T12:50:47.196120Z",
     "start_time": "2023-10-12T12:50:45.635368Z"
    }
   },
   "id": "5f7d1f848a76a78d"
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pyspark.sql.functions as f\n",
    "def makejsonstring(soft_skills,skills):\n",
    "    return json.dumps({\"soft_skills\":soft_skills,\"skills\":skills})\n",
    "udf_makejsonstring = f.udf(makejsonstring)\n",
    "hackdata.withColumn(\"skills\", f.split(\"skills\",\";\")).withColumn(\"soft_skills\", f.split(\"soft_skills\",\";\")).withColumn(\"skillset\", udf_makejsonstring(\"soft_skills\",\"skills\")).drop(\"skills\",\"soft_skills\").repartition(1).write.mode(\"overwrite\").format(\"csv\").save(\"/Users/eashvrudhula/PycharmProjects/Hackathon3/PostgresData/hackathon_data_modified_csv_new\",header=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-12T12:55:34.552941Z",
     "start_time": "2023-10-12T12:54:53.434909Z"
    }
   },
   "id": "f69eacdf77dcfc85"
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df.write.jdbc(url=url, table=\"job_data\", mode='append',properties=properties)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-12T13:12:44.069929Z",
     "start_time": "2023-10-12T13:10:18.630564Z"
    }
   },
   "id": "62c97f638ec63e0c"
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "hackdata.withColumn(\"skills\", f.split(\"skills\",\";\")).withColumn(\"soft_skills\", f.split(\"soft_skills\",\";\")).withColumn(\"skillset\", udf_makejsonstring(\"soft_skills\",\"skills\")).drop(\"skills\",\"soft_skills\").write.mode(\"overwrite\").parquet(\"/Users/eashvrudhula/PycharmProjects/Hackathon3/PostgresData/hackathon_data_modified\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-12T13:02:05.570655Z",
     "start_time": "2023-10-12T13:01:42.241258Z"
    }
   },
   "id": "fe2866c835967b2e"
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [],
   "source": [
    "df = spark.read.parquet(\"/Users/eashvrudhula/PycharmProjects/Hackathon3/PostgresData/hackathon_data_modified\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-12T13:02:07.183341Z",
     "start_time": "2023-10-12T13:02:05.586453Z"
    }
   },
   "id": "9deb575395cde139"
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "|experience        |\n",
      "+------------------+\n",
      "|NULL              |\n",
      "|NULL              |\n",
      "|4.96              |\n",
      "|5.865000076293946 |\n",
      "|4.200000076293946 |\n",
      "|NULL              |\n",
      "|4.874999961853027 |\n",
      "|4.720000228881836 |\n",
      "|6.399999923706055 |\n",
      "|3.5750000762939456|\n",
      "|5.755000076293945 |\n",
      "|NULL              |\n",
      "|6.07              |\n",
      "|4.28              |\n",
      "|4.630000076293945 |\n",
      "|5.925000152587891 |\n",
      "|4.200000076293946 |\n",
      "|4.96              |\n",
      "|4.96              |\n",
      "|4.380000076293945 |\n",
      "|4.585             |\n",
      "|4.449999771118164 |\n",
      "|5.539999923706055 |\n",
      "|4.289999923706055 |\n",
      "|4.970000228881836 |\n",
      "|4.96              |\n",
      "|5.470000228881836 |\n",
      "|4.170000038146973 |\n",
      "|4.28              |\n",
      "|NULL              |\n",
      "|NULL              |\n",
      "|NULL              |\n",
      "|3.0               |\n",
      "|NULL              |\n",
      "|NULL              |\n",
      "|NULL              |\n",
      "|NULL              |\n",
      "|3.0               |\n",
      "|NULL              |\n",
      "|NULL              |\n",
      "|3.0               |\n",
      "|NULL              |\n",
      "|NULL              |\n",
      "|NULL              |\n",
      "|NULL              |\n",
      "|3.0               |\n",
      "|NULL              |\n",
      "|NULL              |\n",
      "|NULL              |\n",
      "|3.9500000762939456|\n",
      "|NULL              |\n",
      "|NULL              |\n",
      "|3.0               |\n",
      "|NULL              |\n",
      "|3.0               |\n",
      "|NULL              |\n",
      "|NULL              |\n",
      "|NULL              |\n",
      "|12.59000015       |\n",
      "|12.59000015       |\n",
      "|12.59000015       |\n",
      "|12.01000023       |\n",
      "|12.59000015       |\n",
      "|12.59000015       |\n",
      "|12.59000015       |\n",
      "|12.59000015       |\n",
      "|12.59000015       |\n",
      "|12.59000015       |\n",
      "|12.59000015       |\n",
      "|12.59000015       |\n",
      "|12.59000015       |\n",
      "|12.59000015       |\n",
      "|12.59000015       |\n",
      "|12.59000015       |\n",
      "|12.59000015       |\n",
      "|12.59000015       |\n",
      "|12.59000015       |\n",
      "|12.59000015       |\n",
      "|12.59000015       |\n",
      "|12.59000015       |\n",
      "|12.59000015       |\n",
      "|12.59000015       |\n",
      "|NULL              |\n",
      "|NULL              |\n",
      "|1.24              |\n",
      "|NULL              |\n",
      "|NULL              |\n",
      "|NULL              |\n",
      "|NULL              |\n",
      "|NULL              |\n",
      "|NULL              |\n",
      "|NULL              |\n",
      "|NULL              |\n",
      "|NULL              |\n",
      "|NULL              |\n",
      "|NULL              |\n",
      "|NULL              |\n",
      "|NULL              |\n",
      "|NULL              |\n",
      "|NULL              |\n",
      "+------------------+\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df.select(\"experience\").show(100,False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-12T13:09:38.293754Z",
     "start_time": "2023-10-12T13:09:36.246994Z"
    }
   },
   "id": "692bc627726c385c"
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "outputs": [],
   "source": [
    "company_data_df = spark.read.format(\"csv\").load(\"/Users/eashvrudhula/PycharmProjects/Hackathon3/PostgresData/company_synon_descriptions.csv\",header = True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-12T14:14:12.362232Z",
     "start_time": "2023-10-12T14:14:09.902586Z"
    }
   },
   "id": "b0d7e02b51f27fee"
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- company_name: string (nullable = true)\n",
      " |-- description: string (nullable = true)\n"
     ]
    }
   ],
   "source": [
    "company_data_df.printSchema()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-12T14:14:12.374116Z",
     "start_time": "2023-10-12T14:14:12.361284Z"
    }
   },
   "id": "ca4dd8bd670b192d"
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "outputs": [],
   "source": [
    "properties = {\n",
    "            \"user\": \"postgres\",\n",
    "            \"password\": \"$Eash1312#\",\n",
    "            \"driver\": \"org.postgresql.Driver\"\n",
    "}\n",
    "driver = \"postgresql\"\n",
    "hostname = \"localhost\"\n",
    "port = \"5432\"\n",
    "database = \"postgres\"\n",
    "username = \"postgres\"\n",
    "password = \"JDCrafters\"\n",
    "url = \"jdbc:{0}://{1}:{2}/{3}?user={4}&password={5}\".format(driver, hostname, port, database, username, password)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-12T15:03:17.765693Z",
     "start_time": "2023-10-12T15:03:17.736952Z"
    }
   },
   "id": "fd7f29ac55c0aa62"
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "company_data_df.write.jdbc(url=url, table=\"company_description_table\", mode='append',properties=properties)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-12T14:14:24.963472Z",
     "start_time": "2023-10-12T14:14:19.940177Z"
    }
   },
   "id": "f2e505f83cc6896b"
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "outputs": [],
   "source": [
    "table = \"company_description_table\"\n",
    "# query = \"SELECT * FROM {0}\".format(table)\n",
    "query = \"SELECT company_name,description from company_description_table WHERE company_name ILIKE '%google%'\"\n",
    "company_data_df_read = spark.read.format('jdbc').options(\n",
    "                url=url,\n",
    "                database=database,\n",
    "                dbtable=\"({0}) as t\".format(query) if query else \"{0}.{1}\".format(database, table),\n",
    "            ).load()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-12T14:22:59.076496Z",
     "start_time": "2023-10-12T14:22:58.107104Z"
    }
   },
   "id": "97b80f7c75b5c5cf"
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 63:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|company_name|description                                                                                                                                                                                                                                                                                                                                                                                           |\n",
      "+------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|Google Inc. |Google Inc., a subsidiary of Alphabet Inc., is a multinational technology company known for its internet-related services and products. Google offers a wide range of services, including search engine, online advertising technologies, cloud computing, software applications, and hardware devices. They strive to organize the world's information and make it universally accessible and useful.|\n",
      "+------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "company_data_df_read.show(100,False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-12T14:23:03.506061Z",
     "start_time": "2023-10-12T14:23:01.690663Z"
    }
   },
   "id": "a3becfc605abcb11"
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "outputs": [],
   "source": [
    "glassdoor = spark.read.format(\"csv\").load(\"/Users/eashvrudhula/PycharmProjects/Hackathon3/PostgresData/hackathon_glassdoor_data.csv\",header = True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-12T13:37:20.303020Z",
     "start_time": "2023-10-12T13:37:19.087385Z"
    }
   },
   "id": "366000b11499c0a0"
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _c0: string (nullable = true)\n",
      " |-- job_title_lemmatized1: string (nullable = true)\n",
      " |-- company_name: string (nullable = true)\n",
      " |-- job_title_lemmatized3: string (nullable = true)\n",
      " |-- jobTitle: string (nullable = true)\n",
      " |-- cultureAndValuesRating: string (nullable = true)\n",
      " |-- compensationAndBenefitsRating: string (nullable = true)\n",
      " |-- ceoApproval: string (nullable = true)\n",
      " |-- isFeaturedReview: string (nullable = true)\n",
      " |-- workLifeBalanceRating: string (nullable = true)\n",
      " |-- overallNumeric: string (nullable = true)\n",
      " |-- overall: string (nullable = true)\n",
      " |-- synonimised_company_name: string (nullable = true)\n",
      " |-- job_role: string (nullable = true)\n"
     ]
    }
   ],
   "source": [
    "glassdoor.drop(\"\").printSchema()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-12T13:37:22.555608Z",
     "start_time": "2023-10-12T13:37:22.496066Z"
    }
   },
   "id": "64356631751892e9"
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/10/12 19:11:11 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: job_title_lemmatized, company_name, jobTitle, cultureAndValuesRating, compensationAndBenefitsRating, ceoApproval, isFeaturedReview, workLifeBalanceRating, overallNumeric, overall, synonimised_company_name, job_role\n",
      " Schema: job_title_lemmatized1, company_name, jobTitle, cultureAndValuesRating, compensationAndBenefitsRating, ceoApproval, isFeaturedReview, workLifeBalanceRating, overallNumeric, overall, synonimised_company_name, job_role\n",
      "Expected: job_title_lemmatized1 but found: job_title_lemmatized\n",
      "CSV file: file:///Users/eashvrudhula/PycharmProjects/Hackathon3/PostgresData/hackathon_glassdoor_data.csv\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "glassdoor.drop(\"_c0\",\"job_title_lemmatized3\").withColumnRenamed(\"job_title_lemmatized1\",\"job_title_lemmatized\").write.jdbc(url=url, table=\"glassdoor_reviews\", mode='append',properties=properties)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-12T13:42:57.083860Z",
     "start_time": "2023-10-12T13:41:10.093965Z"
    }
   },
   "id": "d93850f587ab13e0"
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "outputs": [],
   "source": [
    "table = \"job_data\"\n",
    "query = \"SELECT * FROM {0}\".format(table)\n",
    "company_data_df_read = spark.read.format('jdbc').options(\n",
    "                url=url,\n",
    "                database=database,\n",
    "                dbtable=\"({0}) as t\".format(query) if query else \"{0}.{1}\".format(database, table),\n",
    "            ).load()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-12T15:04:49.239387Z",
     "start_time": "2023-10-12T15:04:48.960603Z"
    }
   },
   "id": "acd55181fb8549c2"
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: integer (nullable = true)\n",
      " |-- job_role: string (nullable = true)\n",
      " |-- job_description: string (nullable = true)\n",
      " |-- skillset: string (nullable = true)\n",
      " |-- responsibility: string (nullable = true)\n",
      " |-- location_name: string (nullable = true)\n",
      " |-- talent_cost: decimal(38,18) (nullable = true)\n",
      " |-- currency_code: string (nullable = true)\n",
      " |-- currency: string (nullable = true)\n",
      " |-- experience: decimal(38,18) (nullable = true)\n",
      " |-- experience_range: string (nullable = true)\n",
      " |-- ready_for_application: boolean (nullable = true)\n",
      " |-- city: string (nullable = true)\n",
      " |-- country: string (nullable = true)\n"
     ]
    }
   ],
   "source": [
    "company_data_df_read.printSchema()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-12T15:04:49.782780Z",
     "start_time": "2023-10-12T15:04:49.765526Z"
    }
   },
   "id": "8ba9f49b6dbb02b8"
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "outputs": [],
   "source": [
    "a = company_data_df_read.rdd.map(lambda x: x.asDict()).collect()[0]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-12T14:23:10.528823Z",
     "start_time": "2023-10-12T14:23:09.644883Z"
    }
   },
   "id": "f31cf619dd335bc9"
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'company_name': 'Google Inc.', 'description': \"Google Inc., a subsidiary of Alphabet Inc., is a multinational technology company known for its internet-related services and products. Google offers a wide range of services, including search engine, online advertising technologies, cloud computing, software applications, and hardware devices. They strive to organize the world's information and make it universally accessible and useful.\"}\n"
     ]
    }
   ],
   "source": [
    "print(a)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-12T14:23:11.114022Z",
     "start_time": "2023-10-12T14:23:11.088309Z"
    }
   },
   "id": "1a84a0753c6544f0"
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "outputs": [],
   "source": [
    "queries = {\n",
    "    \"responsibilites_and_skills\": \"a\",\n",
    "    \"about_company\": \"b\",\n",
    "    \"salary\":\"c\"\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-12T16:21:02.485443Z",
     "start_time": "2023-10-12T16:21:02.464999Z"
    }
   },
   "id": "e541a0de498a3311"
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "responsibilites_and_skills\n",
      "a\n",
      "about_company\n",
      "b\n",
      "salary\n",
      "c\n"
     ]
    }
   ],
   "source": [
    "for key_names in queries:\n",
    "    print(key_names)\n",
    "    print(queries[key_names])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-12T16:22:18.604952Z",
     "start_time": "2023-10-12T16:22:18.576757Z"
    }
   },
   "id": "35633c4c5c6e68b0"
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "outputs": [],
   "source": [
    "response_json = {\n",
    "    \"about_company\": [\n",
    "        [\n",
    "            226193,\n",
    "            \"Google Inc.\",\n",
    "            \"Google Inc., a subsidiary of Alphabet Inc., is a multinational technology company known for its internet-related services and products. Google offers a wide range of services, including search engine, online advertising technologies, cloud computing, software applications, and hardware devices. They strive to organize the world's information and make it universally accessible and useful.\"\n",
    "        ]\n",
    "    ],\n",
    "    \"responsibilites_and_skills\": [\n",
    "        [\n",
    "            \"DevOps Engineer\",\n",
    "            \"The role is responsible for designing, developing, and maintaining CI/CD pipelines to automate software build, testing, deployment, and monitoring processes. The role collaborates with development teams to understand application requirements, architecture, and infrastructure needs to fullfill the needs without any correction. The role monitors and maintain production systems, troubleshoot issues, and perform root cause analysis to prevent future incidents.\",\n",
    "            \"Deploy, automate, maintaining, and manage cloud-based system, to ensure the availability, performance, scalability, and security of production systems; Investigate and resolve technical issues by deploying updates and fixes; Collect and review customers feedback to enhance user experience; Update the processes and design new processes as needed to optimize performance; Test system integrity, implement designs, application developments, and other processes related to infrastructure, making improvements as needed; Manage and support integration of new technologies; Ensure that systems are safe and secure against cybersecurity threats;\\n<p><strong>Emerging Functional Skills</strong></p>\\n<ul>\\n<li>Knowledge of Scripting Languages such as <strong>Bash</strong>, <strong>Powershell</strong></li>\\n<li>Experience in <strong>Agile Methodologies</strong></li>\\n<li>Familiarity with Database Management Software tool like <strong>SQL</strong></li>\\n<li>Experience in Programming Languages such a <strong>Java</strong>, <strong>Python</strong></li>\\n<li>Knowledge of Cloud technologies tools such as <strong>Amazon Web Services</strong> (AWS)</li>\\n</ul>;\\n<p><strong>Key Behavioural Skills</strong></p>\\n<ul>\\n<li><strong>Analytical</strong></li>\\n<li>collaborative</li>\\n<li><strong>Critical Thinking</strong></li>\\n<li>Integrity</li>\\n<li>Multitasking</li>\\n</ul>\",\n",
    "            \"{\\\"soft_skills\\\": [\\\"Collaboration\\\", \\\" Flexibility\\\", \\\" Multitasking\\\", \\\" Planning\\\", \\\" Client Handling\\\", \\\" Supportive\\\", \\\" Problem Solving\\\", \\\" Business Acumen\\\", \\\" Quality Orientation\\\", \\\" Tenacity\\\"], \\\"skills\\\": [\\\"Software Development\\\", \\\" Scripting\\\", \\\" Git\\\", \\\" Apache Subversion\\\", \\\" Jenkins\\\", \\\" Travis CI\\\", \\\" Splunk\\\", \\\" Server Operations\\\", \\\" Ansible\\\", \\\" Saltstack\\\", \\\" VMware ESXi\\\", \\\" OpenStack\\\", \\\" Xen\\\"]}\"\n",
    "        ]\n",
    "    ]\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-12T17:15:48.960990Z",
     "start_time": "2023-10-12T17:15:48.952533Z"
    }
   },
   "id": "8fe0e376281c5573"
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "outputs": [
    {
     "data": {
      "text/plain": "'The role is responsible for designing, developing, and maintaining CI/CD pipelines to automate software build, testing, deployment, and monitoring processes. The role collaborates with development teams to understand application requirements, architecture, and infrastructure needs to fullfill the needs without any correction. The role monitors and maintain production systems, troubleshoot issues, and perform root cause analysis to prevent future incidents.'"
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response_json[\"responsibilites_and_skills\"][0][1]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-12T17:16:02.170352Z",
     "start_time": "2023-10-12T17:16:02.139511Z"
    }
   },
   "id": "fa88e1c30ae03828"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "69c94b71c8ba32ca"
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "outputs": [],
   "source": [
    "responsibilites_and_skills = response_json.get('responsibilites_and_skills', None)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-12T17:16:40.286646Z",
     "start_time": "2023-10-12T17:16:40.242503Z"
    }
   },
   "id": "b9a728257418a814"
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "outputs": [
    {
     "data": {
      "text/plain": "'DevOps Engineer'"
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "responsibilites_and_skills[0][0]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-12T17:17:01.827199Z",
     "start_time": "2023-10-12T17:17:01.801991Z"
    }
   },
   "id": "7614d1ed5c1bf41"
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "outputs": [],
   "source": [
    "if responsibilites_and_skills:\n",
    "    job_title = responsibilites_and_skills[0][0]\n",
    "    job_role_description = responsibilites_and_skills[0][1]\n",
    "    responsibility = responsibilites_and_skills[0][2]\n",
    "    skillset = responsibilites_and_skills[0][3]\n",
    "    core_skills = json.loads(skillset)[\"skills\"]\n",
    "    soft_skills = json.loads(skillset)[\"soft_skills\"]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-12T17:18:02.123338Z",
     "start_time": "2023-10-12T17:18:02.080984Z"
    }
   },
   "id": "94c6c3c7ac929f4e"
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "outputs": [
    {
     "data": {
      "text/plain": "'The role is responsible for designing, developing, and maintaining CI/CD pipelines to automate software build, testing, deployment, and monitoring processes. The role collaborates with development teams to understand application requirements, architecture, and infrastructure needs to fullfill the needs without any correction. The role monitors and maintain production systems, troubleshoot issues, and perform root cause analysis to prevent future incidents.'"
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_role_description"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-12T17:19:01.812729Z",
     "start_time": "2023-10-12T17:19:01.780770Z"
    }
   },
   "id": "ae6dacbd8c8cb078"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "responsibility"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "40a2485fa4c5598d"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
